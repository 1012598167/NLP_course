{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:04:21.678220Z",
     "start_time": "2020-11-20T07:04:14.251089Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input,LSTM,Dense\n",
    "from keras.models import Model,load_model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:16.468982Z",
     "start_time": "2020-11-20T07:05:16.464008Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files\\graphviz-2.38\\release\\bin'\n",
    "#我的graphviz环境没配好，为了后面的Plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:19.801075Z",
     "start_time": "2020-11-20T07:05:19.792098Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(n_input,n_output,n_units):\n",
    "    #训练阶段\n",
    "    #encoder\n",
    "    encoder_input = Input(shape = (None, n_input))#############################\n",
    "    #encoder输入维度n_input为每个时间步的输入xt的维度，这里是用来one-hot的英文字符数\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    #n_units为LSTM单元中每个门的神经元的个数，return_state设为True时才会返回最后时刻的状态h,c\n",
    "    _,encoder_h,encoder_c = encoder(encoder_input)\n",
    "    encoder_state = [encoder_h,encoder_c]######################\n",
    "    #保留下来encoder的末状态作为decoder的初始状态\n",
    "    \n",
    "    #decoder\n",
    "    decoder_input = Input(shape = (None, n_output))##########################\n",
    "    #decoder的输入维度为中文字符数\n",
    "    decoder = LSTM(n_units,return_sequences=True, return_state=True)\n",
    "    #训练模型时需要decoder的输出序列来与结果对比优化，故return_sequences也要设为True\n",
    "    decoder_output, _, _ = decoder(decoder_input,initial_state=encoder_state)\n",
    "    #在训练阶段只需要用到decoder的输出序列，不需要用最终状态h.c\n",
    "    decoder_dense = Dense(n_output,activation='softmax')\n",
    "    decoder_output = decoder_dense(decoder_output)\n",
    "    #输出序列经过全连接层得到结果\n",
    "    \n",
    "    #生成的训练模型\n",
    "    model = Model([encoder_input,decoder_input],decoder_output)\n",
    "    #第一个参数为训练模型的输入，包含了encoder和decoder的输入，第二个参数为模型的输出，包含了decoder的输出\n",
    "    \n",
    "    #推理阶段，用于预测过程\n",
    "    #推断模型—encoder\n",
    "    encoder_infer = Model(encoder_input,encoder_state)#####################\n",
    "    \n",
    "    #推断模型-decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))    \n",
    "    decoder_state_input = [decoder_state_input_h, decoder_state_input_c]#上个时刻的状态h,c   ###################\n",
    "    \n",
    "    decoder_infer_output, decoder_infer_state_h, decoder_infer_state_c = decoder(decoder_input,initial_state=decoder_state_input)\n",
    "    decoder_infer_state = [decoder_infer_state_h, decoder_infer_state_c]#当前时刻得到的状态\n",
    "    decoder_infer_output = decoder_dense(decoder_infer_output)#当前时刻的输出\n",
    "    decoder_infer = Model([decoder_input]+decoder_state_input,[decoder_infer_output]+decoder_infer_state)####################\n",
    "    \n",
    "    return model, encoder_infer, decoder_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T00:19:11.065124Z",
     "start_time": "2020-11-30T00:19:11.060138Z"
    }
   },
   "outputs": [],
   "source": [
    "N_UNITS = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 140#整个数据集跑一遍算一个epoch 而不是算出来的\n",
    "NUM_SAMPLES = 10000   ###晚上改成18000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:24.636166Z",
     "start_time": "2020-11-20T07:05:24.632177Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'data/cmn.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:27.737889Z",
     "start_time": "2020-11-20T07:05:27.535407Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(data_path,header=None).iloc[:NUM_SAMPLES,:,]#header=None 没第一行 不写sep默认空格为分隔符\n",
    "df.columns=['inputs','targets']\n",
    "\n",
    "df['targets'] = df['targets'].apply(lambda x: '\\t'+x+'\\n')\n",
    "\n",
    "input_texts = df.inputs.values.tolist()\n",
    "target_texts = df.targets.values.tolist()\n",
    "\n",
    "input_characters = sorted(list(set(df.inputs.unique().sum())))#abcdefg...\n",
    "target_characters = sorted(list(set(df.targets.unique().sum())))#我你他..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:26:21.933985Z",
     "start_time": "2020-12-04T06:26:21.878136Z"
    }
   },
   "outputs": [],
   "source": [
    "input_texts_test = pd.read_table(data_path,header=None).iloc[19934:20134,:,][0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:40:07.713233Z",
     "start_time": "2020-12-04T06:40:07.654391Z"
    }
   },
   "outputs": [],
   "source": [
    "input_characters_text = sorted(list(set(pd.read_table(data_path,header=None).iloc[19934:20134,:,][0].unique().sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:40:08.061305Z",
     "start_time": "2020-12-04T06:40:08.058310Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dict_test = {char:index for index,char in enumerate(input_characters_text)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:32:22.599039Z",
     "start_time": "2020-12-04T06:32:22.589065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom was admiring my new car at the time the truck crashed into it.',\n",
       " 'You must have been surprised to meet your teacher in such a place.',\n",
       " \"You've worked hard for months and have certainly earned a holiday.\",\n",
       " 'The good die young is an old saying which may or may not be true.',\n",
       " \"A bookstore in that location wouldn't make enough money to survive.\",\n",
       " 'Because of his wealth, he was able to become a member of that club.',\n",
       " 'Everyone is anxious to know what has become of the former champion.',\n",
       " \"First off, I'd like you to come with me to a department store sale.\",\n",
       " \"He always left the problem of his children's education to his wife.\",\n",
       " 'He announced that he would come at once and investigate the matter.',\n",
       " 'He devoted the last years of his life to writing his autobiography.',\n",
       " 'He was always annoyed in the city by noises of one sort or another.',\n",
       " 'His wife is in the hospital because she was injured in a car crash.',\n",
       " \"I'm not a child, but sometimes you talk to me as if I were a child.\",\n",
       " 'If you heard her speak English, you would take her for an American.',\n",
       " \"In this kind of weather, it's best to stay home and not go outside.\",\n",
       " 'It took me more than two hours to translate a few pages of English.',\n",
       " 'It was through his influence that she became interested in ecology.',\n",
       " \"Please don't forget to put a stamp on the letter before mailing it.\",\n",
       " 'The teacher pointed her finger at me and asked me to come with her.',\n",
       " 'The value of the painting was estimated at several million dollars.',\n",
       " 'There are many more students in the classroom today than yesterday.',\n",
       " 'There was a minute of silence and then everybody started screaming.',\n",
       " \"This is a secret just between you and me, so don't let it slip out.\",\n",
       " 'This problem is too difficult for primary school children to solve.',\n",
       " 'You should apologize to Dad for not coming home in time for supper.',\n",
       " \"You're going to wreck your eyesight if you play games all the time.\",\n",
       " 'According to the guidebook, this is the best restaurant around here.',\n",
       " 'Father makes sure that all the lights are off before he goes to bed.',\n",
       " \"I can't remember the meaning of the word that I looked up yesterday.\",\n",
       " \"I've never lived on a farm, but both of my parents grew up on farms.\",\n",
       " 'If two men always have the same opinion, one of them is unnecessary.',\n",
       " 'In some countries, the punishment for treason can be life in prison.',\n",
       " 'In the light of what you told us, I think we should revise our plan.',\n",
       " \"It's difficult for me to understand French when it's spoken quickly.\",\n",
       " 'My father is in the habit of reading the newspaper before breakfast.',\n",
       " 'Our task has been easy so far, but it will be difficult from now on.',\n",
       " 'The death penalty had been done away with in many states in the USA.',\n",
       " \"The flash wasn't working, so he couldn't take a picture in the dark.\",\n",
       " 'The only difference between a bad cook and a poisoner is the intent.',\n",
       " \"Tom asked me to tell you he didn't plan on going to Boston with you.\",\n",
       " 'Do you know when they will arrive? \"At eleven-thirty this evening.\"',\n",
       " 'Always do right. This will gratify some people and astonish the rest.',\n",
       " 'Everybody talks about the weather, but nobody does anything about it.',\n",
       " 'He and I were inseparable friends during our time together in school.',\n",
       " 'His intelligence and experience enabled him to deal with the trouble.',\n",
       " \"I think it's dangerous to climb a mountain on a day when it's stormy.\",\n",
       " \"If it had not been for your help, I couldn't have completed the work.\",\n",
       " \"In a few minutes we'll be landing at New Tokyo International Airport.\",\n",
       " \"It's clear that there's a rather strong disagreement between the two.\",\n",
       " 'Most Americans do not object to my calling them by their first names.',\n",
       " \"Nobody's going to shed any tears if that old building gets torn down.\",\n",
       " 'She has a good command of English though she was brought up in Japan.',\n",
       " 'She took full advantage of her stay in London to improve her English.',\n",
       " 'The taller the tree, the more likely it is to be struck by lightning.',\n",
       " 'There is nothing worse than doing something in a half-hearted manner.',\n",
       " \"We've received a lot of applications in answer to our advertisements.\",\n",
       " 'Because of heavy snow, the plane from Beijing arrived 20 minutes late.',\n",
       " 'Can you describe to me the difference between black tea and green tea?',\n",
       " \"Don't worry! Even if I drink, it doesn't have an effect on my driving.\",\n",
       " 'Had he known what was about to happen, he would have changed his plan.',\n",
       " 'I think you will find it convenient to put a short-cut on the desktop.',\n",
       " \"I want a cellular phone, but I don't have enough money to pay for one.\",\n",
       " 'I will have finished reading this novel by the time you come tomorrow.',\n",
       " \"I've something interesting to tell you that you might find surprising.\",\n",
       " 'It was raining when we left, but by the time we arrived, it was sunny.',\n",
       " 'Rather than live a hundred years as a rabbit, live one day as a tiger.',\n",
       " 'Tom wanted to stay home and relax instead of hiking with his children.',\n",
       " \"What's this song? I've heard it before, but I can't remember the name.\",\n",
       " 'As is evident from the data, smoking is not decreasing among the young.',\n",
       " 'Because it is written in simple English even a child can understand it.',\n",
       " 'Does any other country fan the flames of patriotism as much as America?',\n",
       " 'I was nine years old when I asked my mom if Santa Claus really existed.',\n",
       " \"I'm a foreigner and I don't know Czech very well. Please, speak slowly.\",\n",
       " \"If it's at all possible, I'd like you to take part in the next meeting.\",\n",
       " 'If you enjoy the work you do, you have something worth more than money.',\n",
       " \"It was not until I had a baby myself that I knew what mother's love is.\",\n",
       " 'Kindness is the language which the deaf can hear and the blind can see.',\n",
       " 'Mary came home from school in tears because her friends had teased her.',\n",
       " 'My father was no less affectionate and tender to me than my mother was.',\n",
       " \"Now's the time to decide whether you really want to get married or not.\",\n",
       " 'People show up bright on an infrared camera because of their body heat.',\n",
       " 'The police have been searching for the stolen goods for almost a month.',\n",
       " 'They told me that I would feel a little better if I took this medicine.',\n",
       " \"Tom couldn't go to college because his family didn't have enough money.\",\n",
       " 'When his food supply ran short, he had to look for a new place to live.',\n",
       " 'While I was reading in bed last night, I fell asleep with the light on.',\n",
       " 'Where have you been? \"I have been to the station to see a friend off.\"',\n",
       " 'Her eyes shone with joy when she saw that her mother was not mad at her.',\n",
       " 'I can place the palms of my hands on the floor without bending my knees.',\n",
       " 'I was planning on going to the beach today, but then it started to rain.',\n",
       " \"If we knew what we were doing, it wouldn't be called research, would it?\",\n",
       " \"If you want to go, then go. If you don't want to, then it's no big deal.\",\n",
       " 'In the U.S., most people can vote when they reach eighteen years of age.',\n",
       " 'It is the things that we do not possess which seem to us most desirable.',\n",
       " \"Rather than cutting down on cigarettes, why don't you just give them up?\",\n",
       " 'Sociopaths rarely display remorse or feelings of guilt for their crimes.',\n",
       " \"Tom can't account for his whereabouts on the day that Mary was murdered.\",\n",
       " 'Tom never forgets to give his wife flowers on their wedding anniversary.',\n",
       " 'Tom was able to make himself understood in French when he visited Paris.',\n",
       " \"We were talking about something at that time, but I don't remember what.\",\n",
       " \"You shouldn't share too much private information on the social networks.\",\n",
       " 'After school, I go to an English school to practice English conversation.',\n",
       " \"I think you'll have very little difficulty in getting a driver's license.\",\n",
       " 'I thought we had found the perfect hiding place, but the police found us.',\n",
       " \"I'd like to know the phone number of the nearest American Express office.\",\n",
       " 'She visits the dentist on a regular basis, so she seldom gets toothaches.',\n",
       " \"To make matters worse, he isn't even conscious of annoying his neighbors.\",\n",
       " 'You seem to be prejudiced against ideas that come from foreign countries.',\n",
       " 'If a sick person folds one thousand paper cranes, her wish will come true.',\n",
       " \"It's hard to believe that Tom wasn't aware that Mary was in love with him.\",\n",
       " 'Tom returned to his hometown to visit his parents during the summer break.',\n",
       " \"You're much less likely to get a good position if you don't speak English.\",\n",
       " 'After asking for my key at the front desk, I took the elevator to my floor.',\n",
       " 'English has now become the common language of several nations in the world.',\n",
       " 'Outside the school, she saw people with no homes living in cardboard boxes.',\n",
       " \"The Prime Minister's speech was calculated to anger the opposition parties.\",\n",
       " \"The good thing about this electronic dictionary is that it's easy to carry.\",\n",
       " 'The lady really flipped out when she learned she had won a million dollars.',\n",
       " 'We apologize for the delay and regret any inconvenience it may have caused.',\n",
       " 'According to newspaper reports, there was an airplane accident last evening.',\n",
       " 'After he had graduated from the university, he taught English for two years.',\n",
       " 'If a man had 11 sheep and all but 9 died, how many sheep would he have left?',\n",
       " \"It would take me too much time to explain to you why it's not going to work.\",\n",
       " 'The statue of Hachiko, the faithful dog, stands in front of Shibuya Station.',\n",
       " 'A person views things differently according to whether they are rich or poor.',\n",
       " 'Although the government refuses to admit it, its economic policy is in ruins.',\n",
       " 'Mary tied an apron around her waist and then took the turkey out of the oven.',\n",
       " 'People look at things differently depending on whether they are rich or poor.',\n",
       " 'The population of London is much greater than that of any other British city.',\n",
       " \"They consider it impolite to disagree with someone they don't know very well.\",\n",
       " 'Three out of four Americans believe in the existence of paranormal phenomena.',\n",
       " \"Tom came to the conclusion that no matter what he did, Mary wouldn't like it.\",\n",
       " 'All students of English should have a good English-English dictionary at hand.',\n",
       " 'Eighty percent of all information on computers around the world is in English.',\n",
       " \"I've had a scratchy throat since this morning. I wonder if I've caught a cold.\",\n",
       " \"If it looks like an apple and it tastes like an apple, it's probably an apple.\",\n",
       " 'The world is just like a book, and every step you take is like turning a page.',\n",
       " \"Today, I was supposed to study at the library but I woke up around 12 o'clock.\",\n",
       " 'Tom can write almost like a native speaker, but his pronunciation is terrible.',\n",
       " \"Tom did the best he could, but he wasn't able to get a higher grade than Mary.\",\n",
       " 'As the train came to a halt, all of the passengers wondered what was happening.',\n",
       " 'Charles Lindbergh made the first solo flight across the Atlantic Ocean in 1927.',\n",
       " \"His scores are always better than mine, even though he doesn't study very much.\",\n",
       " \"I don't have a lot of work, but it's enough to keep me in the office this week.\",\n",
       " 'I returned the books I borrowed from the library, and I borrowed some new ones.',\n",
       " \"Publication of the article was timed to coincide with the professor's birthday.\",\n",
       " \"She's popular, not because she's beautiful, but because she's kind to everyone.\",\n",
       " 'When I was in London last year, someone broke into my room and stole my wallet.',\n",
       " 'At the time there were no native English speakers teaching in any public school.',\n",
       " 'Rio de Janeiro is perfectly safe as long as you stay out of the dangerous areas.',\n",
       " 'She was asked to convince him to get his son or someone else to paint the house.',\n",
       " \"Even though I studied English for 6 years in school, I'm not good at speaking it.\",\n",
       " 'The ages of the two children put together was equivalent to that of their father.',\n",
       " 'To the man who only has a hammer in the toolkit, every problem looks like a nail.',\n",
       " 'Being a good conversationalist does not just mean being a good speaker of English.',\n",
       " \"Manholes are round because that way they won't accidentally fall through the hole.\",\n",
       " 'You should have known better than to take an examination without preparing for it.',\n",
       " \"I've just spoken to your French teacher and he says you're doing well in his class.\",\n",
       " \"We'll need a head hunting agency to find the right man for this executive position.\",\n",
       " 'He came back not because he was homesick, but because he was running short of money.',\n",
       " \"If you want something to be done right, sometimes you've just got to do it yourself.\",\n",
       " \"Why don't we stop arguing over these piddling matters and get to the issues at hand?\",\n",
       " \"A growing child who doesn't seem to have much energy perhaps needs medical attention.\",\n",
       " 'All things considered, I think you should go back home and take care of your parents.',\n",
       " 'In London, the police are always worried about finding a bomb on the train or subway.',\n",
       " 'Ladies and gentlemen, due to an accident at the airport, our arrival will be delayed.',\n",
       " 'The number of people on Facebook is greater than the population of the United States.',\n",
       " 'Democracy is the worst form of government, except all the others that have been tried.',\n",
       " 'At lunchtime today, our usual restaurant was closed because of a funeral in the family.',\n",
       " \"Tom's mother is a nurse at the hospital that's across the street from where Mary lives.\",\n",
       " 'Eat a live frog every morning, and nothing worse will happen to you the rest of the day.',\n",
       " \"I had to change clothes because what I was wearing wasn't appropriate for the situation.\",\n",
       " 'Computers are certainly playing an important role in our life, whether we like it or not.',\n",
       " \"One out of 455 women doesn't realize she's pregnant until the twentieth week of pregnancy.\",\n",
       " 'Because of its origins, Canadian English has features of both American and British English.',\n",
       " 'I like this picture, not just because it is famous, but because it really is a masterpiece.',\n",
       " 'For the other 600 million people, English is either a second language or a foreign language.',\n",
       " 'Lonely people tend to be afraid of meeting others, which ensures they will always be lonely.',\n",
       " 'When people meet, first impressions determine more than 50 percent of whatever happens next.',\n",
       " 'Right now, we have blueberries, blackberries, cherries, strawberries, peaches and nectarines.',\n",
       " 'Throughout the five years of painful cancer treatments, he managed to keep a stiff upper lip.',\n",
       " 'When we started out, our band could only find small clubs in small cities that would hire us.',\n",
       " 'Abraham Lincoln, the 16th president of the United States, was born in a log cabin in Kentucky.',\n",
       " 'For quantities of 20 or more, we can allow you a special discount of 10% on the prices quoted.',\n",
       " \"I can't believe you are eating something the doctor has told you repeatedly you shouldn't eat.\",\n",
       " 'If we were supposed to talk more than listen, we would have been given two mouths and one ear.',\n",
       " 'Optimists see opportunities in disasters while pessimists find disasters in every opportunity.',\n",
       " \"Tom tried to return the swimsuit for a larger size, but the clerk told him that wasn't allowed.\",\n",
       " 'Some people clung to tree branches for several hours to avoid being washed away by the floodwaters.',\n",
       " 'The handyman was supposed to arrive at twelve noon, but got stuck in a traffic jam for a few hours.',\n",
       " 'My parents usually speak to each other in French, even though my mother is a native English speaker.',\n",
       " 'The large crowd roared in approval as Mark Knopfler played the first few bars of \"Money for Nothing\".',\n",
       " \"Tom's daughter pretended not to know him when he came to pick her up from school in his battered old car.\",\n",
       " \"The Japanese Parliament today officially elected Ryoutarou Hashimoto as the country's 52nd prime minister.\",\n",
       " 'Last year in the Philippines, earthquakes and tidal waves resulted in the deaths of more than 6,000 people.',\n",
       " 'My mother speaks French better than my father speaks English, so they usually speak to each other in French.',\n",
       " \"Even now, I occasionally think I'd like to see you. Not the you that you are today, but the you I remember from the past.\",\n",
       " \"If a person has not had a chance to acquire his target language by the time he's an adult, he's unlikely to be able to reach native speaker level in that language.\"]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:19:53.237549Z",
     "start_time": "2020-12-04T05:19:53.228572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:27:32.756545Z",
     "start_time": "2020-12-04T05:27:32.697743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>嗨。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>你好。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  Hi.   嗨。\n",
       "1  Hi.  你好。"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(data_path,header=None).iloc[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:27:53.886936Z",
     "start_time": "2020-12-04T05:27:53.824104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>嗨。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>你好。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  Hi.   嗨。\n",
       "1  Hi.  你好。"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(data_path,header=None).iloc[:2,:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:33:49.610378Z",
     "start_time": "2020-12-04T05:33:49.553531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hi.', 'Run.', 'Wait!', 'Hello!'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(data_path,header=None).iloc[:5,:,][0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:35:28.030838Z",
     "start_time": "2020-12-04T05:35:27.981969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi.', 'Hi.', 'Run.', 'Wait!', 'Hello!']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(data_path,header=None).iloc[:5,:,][0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:34:04.507964Z",
     "start_time": "2020-12-04T05:34:04.444053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '.', 'H', 'R', 'W', 'a', 'e', 'i', 'l', 'n', 'o', 't', 'u']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set(pd.read_table(data_path,header=None).iloc[:5,:,][0].unique().sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:34:44.032392Z",
     "start_time": "2020-12-04T05:34:43.974032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['。', '你', '嗨', '好', '用', '的', '等', '跑', '！']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(set(pd.read_table(data_path,header=None).iloc[:5,:,][1].unique().sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:29.298691Z",
     "start_time": "2020-11-20T07:05:29.289714Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_LENGTH = max([len(i) for i in input_texts])#最长输入大小=30\n",
    "OUTPUT_LENGTH = max([len(i) for i in target_texts])#最长输出大小=22\n",
    "INPUT_FEATURE_LENGTH = len(input_characters)#词表大小=73\n",
    "OUTPUT_FEATURE_LENGTH = len(target_characters)#词表大小=2623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:28:15.415569Z",
     "start_time": "2020-12-04T06:28:15.406984Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_LENGTH_TEST = max([len(i) for i in input_texts_test])#最长输入大小=163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:28:20.455449Z",
     "start_time": "2020-12-04T06:28:20.448294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_LENGTH_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:37:08.984344Z",
     "start_time": "2020-12-04T05:37:08.977360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2623"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:31.323274Z",
     "start_time": "2020-11-20T07:05:30.795687Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_input = np.zeros((NUM_SAMPLES,INPUT_LENGTH,INPUT_FEATURE_LENGTH))#10000,30,73\n",
    "decoder_input = np.zeros((NUM_SAMPLES,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH))\n",
    "decoder_output = np.zeros((NUM_SAMPLES,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:32.282708Z",
     "start_time": "2020-11-20T07:05:32.272734Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dict = {char:index for index,char in enumerate(input_characters)}\n",
    "input_dict_reverse = {index:char for index,char in enumerate(input_characters)}\n",
    "target_dict = {char:index for index,char in enumerate(target_characters)}\n",
    "target_dict_reverse = {index:char for index,char in enumerate(target_characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T05:37:59.862652Z",
     "start_time": "2020-12-04T05:37:59.852679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '$': 3,\n",
       " '%': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '4': 13,\n",
       " '5': 14,\n",
       " '6': 15,\n",
       " '7': 16,\n",
       " '8': 17,\n",
       " '9': 18,\n",
       " ':': 19,\n",
       " '?': 20,\n",
       " 'A': 21,\n",
       " 'B': 22,\n",
       " 'C': 23,\n",
       " 'D': 24,\n",
       " 'E': 25,\n",
       " 'F': 26,\n",
       " 'G': 27,\n",
       " 'H': 28,\n",
       " 'I': 29,\n",
       " 'J': 30,\n",
       " 'K': 31,\n",
       " 'L': 32,\n",
       " 'M': 33,\n",
       " 'N': 34,\n",
       " 'O': 35,\n",
       " 'P': 36,\n",
       " 'Q': 37,\n",
       " 'R': 38,\n",
       " 'S': 39,\n",
       " 'T': 40,\n",
       " 'U': 41,\n",
       " 'V': 42,\n",
       " 'W': 43,\n",
       " 'Y': 44,\n",
       " 'Z': 45,\n",
       " 'a': 46,\n",
       " 'b': 47,\n",
       " 'c': 48,\n",
       " 'd': 49,\n",
       " 'e': 50,\n",
       " 'f': 51,\n",
       " 'g': 52,\n",
       " 'h': 53,\n",
       " 'i': 54,\n",
       " 'j': 55,\n",
       " 'k': 56,\n",
       " 'l': 57,\n",
       " 'm': 58,\n",
       " 'n': 59,\n",
       " 'o': 60,\n",
       " 'p': 61,\n",
       " 'q': 62,\n",
       " 'r': 63,\n",
       " 's': 64,\n",
       " 't': 65,\n",
       " 'u': 66,\n",
       " 'v': 67,\n",
       " 'w': 68,\n",
       " 'x': 69,\n",
       " 'y': 70,\n",
       " 'z': 71,\n",
       " '’': 72}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{char:index for index,char in enumerate(input_characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:34.417995Z",
     "start_time": "2020-11-20T07:05:34.166666Z"
    }
   },
   "outputs": [],
   "source": [
    "for seq_index,seq in enumerate(input_texts):#['Hi.','Hi.',..]\n",
    "    for char_index, char in enumerate(seq):#'H','i','.'\n",
    "        encoder_input[seq_index,char_index,input_dict[char]] = 1#对应句子，对应句子长度，对应词带位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:41:03.601046Z",
     "start_time": "2020-12-04T06:41:03.571125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom was admiring my new car at the time the truck crashed into it.\n",
      "You must have been surprised to meet your teacher in such a place.\n",
      "You've worked hard for months and have certainly earned a holiday.\n",
      "The good die young is an old saying which may or may not be true.\n",
      "A bookstore in that location wouldn't make enough money to survive.\n",
      "Because of his wealth, he was able to become a member of that club.\n",
      "Everyone is anxious to know what has become of the former champion.\n",
      "First off, I'd like you to come with me to a department store sale.\n",
      "He always left the problem of his children's education to his wife.\n",
      "He announced that he would come at once and investigate the matter.\n",
      "He devoted the last years of his life to writing his autobiography.\n",
      "He was always annoyed in the city by noises of one sort or another.\n",
      "His wife is in the hospital because she was injured in a car crash.\n",
      "I'm not a child, but sometimes you talk to me as if I were a child.\n",
      "If you heard her speak English, you would take her for an American.\n",
      "In this kind of weather, it's best to stay home and not go outside.\n",
      "It took me more than two hours to translate a few pages of English.\n",
      "It was through his influence that she became interested in ecology.\n",
      "Please don't forget to put a stamp on the letter before mailing it.\n",
      "The teacher pointed her finger at me and asked me to come with her.\n",
      "The value of the painting was estimated at several million dollars.\n",
      "There are many more students in the classroom today than yesterday.\n",
      "There was a minute of silence and then everybody started screaming.\n",
      "This is a secret just between you and me, so don't let it slip out.\n",
      "This problem is too difficult for primary school children to solve.\n",
      "You should apologize to Dad for not coming home in time for supper.\n",
      "You're going to wreck your eyesight if you play games all the time.\n",
      "According to the guidebook, this is the best restaurant around here.\n",
      "Father makes sure that all the lights are off before he goes to bed.\n",
      "I can't remember the meaning of the word that I looked up yesterday.\n",
      "I've never lived on a farm, but both of my parents grew up on farms.\n",
      "If two men always have the same opinion, one of them is unnecessary.\n",
      "In some countries, the punishment for treason can be life in prison.\n",
      "In the light of what you told us, I think we should revise our plan.\n",
      "It's difficult for me to understand French when it's spoken quickly.\n",
      "My father is in the habit of reading the newspaper before breakfast.\n",
      "Our task has been easy so far, but it will be difficult from now on.\n",
      "The death penalty had been done away with in many states in the USA.\n",
      "The flash wasn't working, so he couldn't take a picture in the dark.\n",
      "The only difference between a bad cook and a poisoner is the intent.\n",
      "Tom asked me to tell you he didn't plan on going to Boston with you.\n",
      "Do you know when they will arrive? \"At eleven-thirty this evening.\"\n",
      "Always do right. This will gratify some people and astonish the rest.\n",
      "Everybody talks about the weather, but nobody does anything about it.\n",
      "He and I were inseparable friends during our time together in school.\n",
      "His intelligence and experience enabled him to deal with the trouble.\n",
      "I think it's dangerous to climb a mountain on a day when it's stormy.\n",
      "If it had not been for your help, I couldn't have completed the work.\n",
      "In a few minutes we'll be landing at New Tokyo International Airport.\n",
      "It's clear that there's a rather strong disagreement between the two.\n",
      "Most Americans do not object to my calling them by their first names.\n",
      "Nobody's going to shed any tears if that old building gets torn down.\n",
      "She has a good command of English though she was brought up in Japan.\n",
      "She took full advantage of her stay in London to improve her English.\n",
      "The taller the tree, the more likely it is to be struck by lightning.\n",
      "There is nothing worse than doing something in a half-hearted manner.\n",
      "We've received a lot of applications in answer to our advertisements.\n",
      "Because of heavy snow, the plane from Beijing arrived 20 minutes late.\n",
      "Can you describe to me the difference between black tea and green tea?\n",
      "Don't worry! Even if I drink, it doesn't have an effect on my driving.\n",
      "Had he known what was about to happen, he would have changed his plan.\n",
      "I think you will find it convenient to put a short-cut on the desktop.\n",
      "I want a cellular phone, but I don't have enough money to pay for one.\n",
      "I will have finished reading this novel by the time you come tomorrow.\n",
      "I've something interesting to tell you that you might find surprising.\n",
      "It was raining when we left, but by the time we arrived, it was sunny.\n",
      "Rather than live a hundred years as a rabbit, live one day as a tiger.\n",
      "Tom wanted to stay home and relax instead of hiking with his children.\n",
      "What's this song? I've heard it before, but I can't remember the name.\n",
      "As is evident from the data, smoking is not decreasing among the young.\n",
      "Because it is written in simple English even a child can understand it.\n",
      "Does any other country fan the flames of patriotism as much as America?\n",
      "I was nine years old when I asked my mom if Santa Claus really existed.\n",
      "I'm a foreigner and I don't know Czech very well. Please, speak slowly.\n",
      "If it's at all possible, I'd like you to take part in the next meeting.\n",
      "If you enjoy the work you do, you have something worth more than money.\n",
      "It was not until I had a baby myself that I knew what mother's love is.\n",
      "Kindness is the language which the deaf can hear and the blind can see.\n",
      "Mary came home from school in tears because her friends had teased her.\n",
      "My father was no less affectionate and tender to me than my mother was.\n",
      "Now's the time to decide whether you really want to get married or not.\n",
      "People show up bright on an infrared camera because of their body heat.\n",
      "The police have been searching for the stolen goods for almost a month.\n",
      "They told me that I would feel a little better if I took this medicine.\n",
      "Tom couldn't go to college because his family didn't have enough money.\n",
      "When his food supply ran short, he had to look for a new place to live.\n",
      "While I was reading in bed last night, I fell asleep with the light on.\n",
      "Where have you been? \"I have been to the station to see a friend off.\"\n",
      "Her eyes shone with joy when she saw that her mother was not mad at her.\n",
      "I can place the palms of my hands on the floor without bending my knees.\n",
      "I was planning on going to the beach today, but then it started to rain.\n",
      "If we knew what we were doing, it wouldn't be called research, would it?\n",
      "If you want to go, then go. If you don't want to, then it's no big deal.\n",
      "In the U.S., most people can vote when they reach eighteen years of age.\n",
      "It is the things that we do not possess which seem to us most desirable.\n",
      "Rather than cutting down on cigarettes, why don't you just give them up?\n",
      "Sociopaths rarely display remorse or feelings of guilt for their crimes.\n",
      "Tom can't account for his whereabouts on the day that Mary was murdered.\n",
      "Tom never forgets to give his wife flowers on their wedding anniversary.\n",
      "Tom was able to make himself understood in French when he visited Paris.\n",
      "We were talking about something at that time, but I don't remember what.\n",
      "You shouldn't share too much private information on the social networks.\n",
      "After school, I go to an English school to practice English conversation.\n",
      "I think you'll have very little difficulty in getting a driver's license.\n",
      "I thought we had found the perfect hiding place, but the police found us.\n",
      "I'd like to know the phone number of the nearest American Express office.\n",
      "She visits the dentist on a regular basis, so she seldom gets toothaches.\n",
      "To make matters worse, he isn't even conscious of annoying his neighbors.\n",
      "You seem to be prejudiced against ideas that come from foreign countries.\n",
      "If a sick person folds one thousand paper cranes, her wish will come true.\n",
      "It's hard to believe that Tom wasn't aware that Mary was in love with him.\n",
      "Tom returned to his hometown to visit his parents during the summer break.\n",
      "You're much less likely to get a good position if you don't speak English.\n",
      "After asking for my key at the front desk, I took the elevator to my floor.\n",
      "English has now become the common language of several nations in the world.\n",
      "Outside the school, she saw people with no homes living in cardboard boxes.\n",
      "The Prime Minister's speech was calculated to anger the opposition parties.\n",
      "The good thing about this electronic dictionary is that it's easy to carry.\n",
      "The lady really flipped out when she learned she had won a million dollars.\n",
      "We apologize for the delay and regret any inconvenience it may have caused.\n",
      "According to newspaper reports, there was an airplane accident last evening.\n",
      "After he had graduated from the university, he taught English for two years.\n",
      "If a man had 11 sheep and all but 9 died, how many sheep would he have left?\n",
      "It would take me too much time to explain to you why it's not going to work.\n",
      "The statue of Hachiko, the faithful dog, stands in front of Shibuya Station.\n",
      "A person views things differently according to whether they are rich or poor.\n",
      "Although the government refuses to admit it, its economic policy is in ruins.\n",
      "Mary tied an apron around her waist and then took the turkey out of the oven.\n",
      "People look at things differently depending on whether they are rich or poor.\n",
      "The population of London is much greater than that of any other British city.\n",
      "They consider it impolite to disagree with someone they don't know very well.\n",
      "Three out of four Americans believe in the existence of paranormal phenomena.\n",
      "Tom came to the conclusion that no matter what he did, Mary wouldn't like it.\n",
      "All students of English should have a good English-English dictionary at hand.\n",
      "Eighty percent of all information on computers around the world is in English.\n",
      "I've had a scratchy throat since this morning. I wonder if I've caught a cold.\n",
      "If it looks like an apple and it tastes like an apple, it's probably an apple.\n",
      "The world is just like a book, and every step you take is like turning a page.\n",
      "Today, I was supposed to study at the library but I woke up around 12 o'clock.\n",
      "Tom can write almost like a native speaker, but his pronunciation is terrible.\n",
      "Tom did the best he could, but he wasn't able to get a higher grade than Mary.\n",
      "As the train came to a halt, all of the passengers wondered what was happening.\n",
      "Charles Lindbergh made the first solo flight across the Atlantic Ocean in 1927.\n",
      "His scores are always better than mine, even though he doesn't study very much.\n",
      "I don't have a lot of work, but it's enough to keep me in the office this week.\n",
      "I returned the books I borrowed from the library, and I borrowed some new ones.\n",
      "Publication of the article was timed to coincide with the professor's birthday.\n",
      "She's popular, not because she's beautiful, but because she's kind to everyone.\n",
      "When I was in London last year, someone broke into my room and stole my wallet.\n",
      "At the time there were no native English speakers teaching in any public school.\n",
      "Rio de Janeiro is perfectly safe as long as you stay out of the dangerous areas.\n",
      "She was asked to convince him to get his son or someone else to paint the house.\n",
      "Even though I studied English for 6 years in school, I'm not good at speaking it.\n",
      "The ages of the two children put together was equivalent to that of their father.\n",
      "To the man who only has a hammer in the toolkit, every problem looks like a nail.\n",
      "Being a good conversationalist does not just mean being a good speaker of English.\n",
      "Manholes are round because that way they won't accidentally fall through the hole.\n",
      "You should have known better than to take an examination without preparing for it.\n",
      "I've just spoken to your French teacher and he says you're doing well in his class.\n",
      "We'll need a head hunting agency to find the right man for this executive position.\n",
      "He came back not because he was homesick, but because he was running short of money.\n",
      "If you want something to be done right, sometimes you've just got to do it yourself.\n",
      "Why don't we stop arguing over these piddling matters and get to the issues at hand?\n",
      "A growing child who doesn't seem to have much energy perhaps needs medical attention.\n",
      "All things considered, I think you should go back home and take care of your parents.\n",
      "In London, the police are always worried about finding a bomb on the train or subway.\n",
      "Ladies and gentlemen, due to an accident at the airport, our arrival will be delayed.\n",
      "The number of people on Facebook is greater than the population of the United States.\n",
      "Democracy is the worst form of government, except all the others that have been tried.\n",
      "At lunchtime today, our usual restaurant was closed because of a funeral in the family.\n",
      "Tom's mother is a nurse at the hospital that's across the street from where Mary lives.\n",
      "Eat a live frog every morning, and nothing worse will happen to you the rest of the day.\n",
      "I had to change clothes because what I was wearing wasn't appropriate for the situation.\n",
      "Computers are certainly playing an important role in our life, whether we like it or not.\n",
      "One out of 455 women doesn't realize she's pregnant until the twentieth week of pregnancy.\n",
      "Because of its origins, Canadian English has features of both American and British English.\n",
      "I like this picture, not just because it is famous, but because it really is a masterpiece.\n",
      "For the other 600 million people, English is either a second language or a foreign language.\n",
      "Lonely people tend to be afraid of meeting others, which ensures they will always be lonely.\n",
      "When people meet, first impressions determine more than 50 percent of whatever happens next.\n",
      "Right now, we have blueberries, blackberries, cherries, strawberries, peaches and nectarines.\n",
      "Throughout the five years of painful cancer treatments, he managed to keep a stiff upper lip.\n",
      "When we started out, our band could only find small clubs in small cities that would hire us.\n",
      "Abraham Lincoln, the 16th president of the United States, was born in a log cabin in Kentucky.\n",
      "For quantities of 20 or more, we can allow you a special discount of 10% on the prices quoted.\n",
      "I can't believe you are eating something the doctor has told you repeatedly you shouldn't eat.\n",
      "If we were supposed to talk more than listen, we would have been given two mouths and one ear.\n",
      "Optimists see opportunities in disasters while pessimists find disasters in every opportunity.\n",
      "Tom tried to return the swimsuit for a larger size, but the clerk told him that wasn't allowed.\n",
      "Some people clung to tree branches for several hours to avoid being washed away by the floodwaters.\n",
      "The handyman was supposed to arrive at twelve noon, but got stuck in a traffic jam for a few hours.\n",
      "My parents usually speak to each other in French, even though my mother is a native English speaker.\n",
      "The large crowd roared in approval as Mark Knopfler played the first few bars of \"Money for Nothing\".\n",
      "Tom's daughter pretended not to know him when he came to pick her up from school in his battered old car.\n",
      "The Japanese Parliament today officially elected Ryoutarou Hashimoto as the country's 52nd prime minister.\n",
      "Last year in the Philippines, earthquakes and tidal waves resulted in the deaths of more than 6,000 people.\n",
      "My mother speaks French better than my father speaks English, so they usually speak to each other in French.\n",
      "Even now, I occasionally think I'd like to see you. Not the you that you are today, but the you I remember from the past.\n",
      "If a person has not had a chance to acquire his target language by the time he's an adult, he's unlikely to be able to reach native speaker level in that language.\n"
     ]
    }
   ],
   "source": [
    "#长句子测试\n",
    "test_long_sentence_input = np.zeros((200,INPUT_LENGTH_TEST,INPUT_FEATURE_LENGTH))#200,163,73\n",
    "for seq_index,seq in enumerate(input_texts_test):#[长句]\n",
    "    print(seq)     \n",
    "    for char_index, char in enumerate(seq):#长句的词\n",
    "        test_long_sentence_input[seq_index,char_index,input_dict_test[char]] = 1#对应句子，对应句子长度，对应词带位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:45:12.314027Z",
     "start_time": "2020-12-04T06:45:12.301062Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 34\n",
      "0 1 52\n",
      "0 2 50\n",
      "0 3 0\n",
      "0 4 60\n",
      "0 5 38\n",
      "0 6 56\n",
      "0 7 0\n",
      "0 8 38\n",
      "0 9 41\n",
      "0 10 50\n",
      "0 11 46\n",
      "0 12 55\n",
      "0 13 46\n",
      "0 14 51\n",
      "0 15 44\n",
      "0 16 0\n",
      "0 17 50\n",
      "0 18 62\n",
      "0 19 0\n",
      "0 20 51\n",
      "0 21 42\n",
      "0 22 60\n",
      "0 23 0\n",
      "0 24 40\n",
      "0 25 38\n",
      "0 26 55\n",
      "0 27 0\n",
      "0 28 38\n",
      "0 29 57\n",
      "0 30 0\n",
      "0 31 57\n",
      "0 32 45\n",
      "0 33 42\n",
      "0 34 0\n",
      "0 35 57\n",
      "0 36 46\n",
      "0 37 50\n",
      "0 38 42\n",
      "0 39 0\n",
      "0 40 57\n",
      "0 41 45\n",
      "0 42 42\n",
      "0 43 0\n",
      "0 44 57\n",
      "0 45 55\n",
      "0 46 58\n",
      "0 47 40\n",
      "0 48 48\n",
      "0 49 0\n",
      "0 50 40\n",
      "0 51 55\n",
      "0 52 38\n",
      "0 53 56\n",
      "0 54 45\n",
      "0 55 42\n",
      "0 56 41\n",
      "0 57 0\n",
      "0 58 46\n",
      "0 59 51\n",
      "0 60 57\n",
      "0 61 52\n",
      "0 62 0\n",
      "0 63 46\n",
      "0 64 57\n",
      "0 65 7\n"
     ]
    }
   ],
   "source": [
    "for char_index, char in enumerate('Tom was admiring my new car at the time the truck crashed into it.'):\n",
    "    print(0,char_index,input_dict_test[char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:45:45.617955Z",
     "start_time": "2020-12-04T06:45:45.612969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 23\n",
      "0 1 46\n",
      "0 2 1\n"
     ]
    }
   ],
   "source": [
    "for char_index, char in enumerate('Hi!'):\n",
    "    print(0,char_index,input_dict_test[char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:43:08.685980Z",
     "start_time": "2020-12-04T06:43:08.678997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_long_sentence_input[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:42:21.690340Z",
     "start_time": "2020-12-04T06:42:21.683356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:42:49.023917Z",
     "start_time": "2020-12-04T06:42:49.015938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input[0,0,:]#Hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:34.982483Z",
     "start_time": "2020-11-20T07:05:34.497780Z"
    }
   },
   "outputs": [],
   "source": [
    "for seq_index,seq in enumerate(target_texts):\n",
    "    for char_index,char in enumerate(seq):\n",
    "        decoder_input[seq_index,char_index,target_dict[char]] = 1.0\n",
    "        if char_index > 0:\n",
    "            decoder_output[seq_index,char_index-1,target_dict[char]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察向量化的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:36.999087Z",
     "start_time": "2020-11-20T07:05:36.981136Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([input_dict_reverse[np.argmax(i)] for i in encoder_input[0] if max(i) !=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:37.202543Z",
     "start_time": "2020-11-20T07:05:37.187584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'嗨。\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([target_dict_reverse[np.argmax(i)] for i in decoder_output[0] if max(i) !=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:37.382068Z",
     "start_time": "2020-11-20T07:05:37.367103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t嗨。\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([target_dict_reverse[np.argmax(i)] for i in decoder_input[0] if max(i) !=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:40.792453Z",
     "start_time": "2020-11-20T07:05:39.434088Z"
    }
   },
   "outputs": [],
   "source": [
    "model_train, encoder_infer, decoder_infer = create_model(INPUT_FEATURE_LENGTH, OUTPUT_FEATURE_LENGTH, N_UNITS)#N_UNITS=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:45.019694Z",
     "start_time": "2020-11-20T07:05:43.899691Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型结构\n",
    "plot_model(to_file='model.png',model=model_train,show_shapes=True)\n",
    "plot_model(to_file='encoder.png',model=encoder_infer,show_shapes=True)\n",
    "plot_model(to_file='decoder.png',model=decoder_infer,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:46.995413Z",
     "start_time": "2020-11-20T07:05:46.976459Z"
    }
   },
   "outputs": [],
   "source": [
    "model_train.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T00:16:51.699793Z",
     "start_time": "2020-11-30T00:16:51.683215Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "optimizer = tfa.optimizers.LazyAdam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T00:16:58.992558Z",
     "start_time": "2020-11-30T00:16:58.877865Z"
    }
   },
   "outputs": [],
   "source": [
    "model_train.compile(optimizer=optimizer, loss='categorical_crossentropy')#optimizer='adam',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:47.640794Z",
     "start_time": "2020-11-20T07:05:47.634697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 73)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 2623)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 337920      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  2949120     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2623)   674111      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,961,151\n",
      "Trainable params: 3,961,151\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:49.610411Z",
     "start_time": "2020-11-20T07:05:49.604427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 73)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 337920    \n",
      "=================================================================\n",
      "Total params: 337,920\n",
      "Trainable params: 337,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_infer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:05:50.162932Z",
     "start_time": "2020-11-20T07:05:50.153956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 2623)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  2949120     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2623)   674111      lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,623,231\n",
      "Trainable params: 3,623,231\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_infer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T11:06:16.477870Z",
     "start_time": "2020-11-20T07:05:51.884327Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 81s 651ms/step - loss: 2.0308 - val_loss: 2.5112\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 79s 629ms/step - loss: 1.9012 - val_loss: 2.3973\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 81s 650ms/step - loss: 1.7976 - val_loss: 2.3110\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 75s 604ms/step - loss: 1.7145 - val_loss: 2.2404\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 76s 612ms/step - loss: 1.6432 - val_loss: 2.1713\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 74s 594ms/step - loss: 1.5706 - val_loss: 2.1161\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 82s 654ms/step - loss: 1.5026 - val_loss: 2.0563\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 75s 601ms/step - loss: 1.4525 - val_loss: 2.0119\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 78s 621ms/step - loss: 1.3950 - val_loss: 1.9759\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 74s 589ms/step - loss: 1.3425 - val_loss: 1.9198\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 76s 610ms/step - loss: 1.3023 - val_loss: 1.8909\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 1.2596 - val_loss: 1.8617\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 75s 599ms/step - loss: 1.2184 - val_loss: 1.8445\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 1.1799 - val_loss: 1.8224\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 1.1465 - val_loss: 1.8240\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 70s 558ms/step - loss: 1.1146 - val_loss: 1.8074\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 1.0832 - val_loss: 1.7886\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 70s 558ms/step - loss: 1.0543 - val_loss: 1.7891\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 73s 585ms/step - loss: 1.0259 - val_loss: 1.7791\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 69s 552ms/step - loss: 0.9987 - val_loss: 1.7741\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 66s 527ms/step - loss: 0.9725 - val_loss: 1.7715\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 67s 536ms/step - loss: 0.9458 - val_loss: 1.7748\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 66s 527ms/step - loss: 0.9211 - val_loss: 1.7666\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 75s 600ms/step - loss: 0.8966 - val_loss: 1.7555\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 66s 526ms/step - loss: 0.8729 - val_loss: 1.7639\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 66s 526ms/step - loss: 0.8497 - val_loss: 1.7695\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 67s 534ms/step - loss: 0.8273 - val_loss: 1.7659\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 75s 598ms/step - loss: 0.8052 - val_loss: 1.7742\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 67s 538ms/step - loss: 0.7848 - val_loss: 1.7743\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 72s 576ms/step - loss: 0.7642 - val_loss: 1.7752\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 69s 549ms/step - loss: 0.7437 - val_loss: 1.7807\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 68s 548ms/step - loss: 0.7249 - val_loss: 1.7798\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 66s 525ms/step - loss: 0.7062 - val_loss: 1.7837\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 0.6877 - val_loss: 1.7935\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 69s 556ms/step - loss: 0.6691 - val_loss: 1.8068\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 72s 578ms/step - loss: 0.6520 - val_loss: 1.8066\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 0.6346 - val_loss: 1.8087\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 66s 525ms/step - loss: 0.6168 - val_loss: 1.8160\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 0.6018 - val_loss: 1.8226\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 72s 575ms/step - loss: 0.5854 - val_loss: 1.8354\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 69s 551ms/step - loss: 0.5691 - val_loss: 1.8373\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 67s 537ms/step - loss: 0.5544 - val_loss: 1.8524\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 75s 602ms/step - loss: 0.5399 - val_loss: 1.8478\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 75s 599ms/step - loss: 0.5255 - val_loss: 1.8612\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 0.5108 - val_loss: 1.8645\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 72s 573ms/step - loss: 0.4970 - val_loss: 1.8769\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 76s 609ms/step - loss: 0.4839 - val_loss: 1.8808\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 74s 591ms/step - loss: 0.4709 - val_loss: 1.8939\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 74s 591ms/step - loss: 0.4581 - val_loss: 1.8938\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 73s 581ms/step - loss: 0.4459 - val_loss: 1.9038\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 78s 624ms/step - loss: 0.4347 - val_loss: 1.9082\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 68s 547ms/step - loss: 0.4218 - val_loss: 1.9260\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 69s 548ms/step - loss: 0.4107 - val_loss: 1.9211\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 66s 531ms/step - loss: 0.3984 - val_loss: 1.9364\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 69s 549ms/step - loss: 0.3886 - val_loss: 1.9485\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 72s 578ms/step - loss: 0.3780 - val_loss: 1.9543\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 77s 615ms/step - loss: 0.3672 - val_loss: 1.9519\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 81s 646ms/step - loss: 0.3577 - val_loss: 1.9605\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 79s 634ms/step - loss: 0.3476 - val_loss: 1.9798\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.3371 - val_loss: 1.9838\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.3287 - val_loss: 1.9937\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 75s 603ms/step - loss: 0.3191 - val_loss: 1.9980\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 74s 593ms/step - loss: 0.3096 - val_loss: 2.0123\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 78s 623ms/step - loss: 0.3014 - val_loss: 2.0142\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 81s 651ms/step - loss: 0.2921 - val_loss: 2.0233\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 76s 608ms/step - loss: 0.2836 - val_loss: 2.0315\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 81s 650ms/step - loss: 0.2753 - val_loss: 2.0465\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 78s 625ms/step - loss: 0.2676 - val_loss: 2.0486\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 77s 617ms/step - loss: 0.2601 - val_loss: 2.0633\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 77s 616ms/step - loss: 0.2510 - val_loss: 2.0693\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 76s 606ms/step - loss: 0.2439 - val_loss: 2.0716\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 75s 599ms/step - loss: 0.2374 - val_loss: 2.0844\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 75s 597ms/step - loss: 0.2287 - val_loss: 2.0884\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 75s 603ms/step - loss: 0.2219 - val_loss: 2.1008\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 75s 598ms/step - loss: 0.2151 - val_loss: 2.1136\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 76s 606ms/step - loss: 0.2083 - val_loss: 2.1111\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 77s 618ms/step - loss: 0.2024 - val_loss: 2.1217\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 76s 608ms/step - loss: 0.1963 - val_loss: 2.1304\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 75s 599ms/step - loss: 0.1893 - val_loss: 2.1429\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 77s 614ms/step - loss: 0.1832 - val_loss: 2.1463\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 78s 628ms/step - loss: 0.1777 - val_loss: 2.1551\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 86s 684ms/step - loss: 0.1708 - val_loss: 2.1607\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 76s 604ms/step - loss: 0.1657 - val_loss: 2.1777\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 79s 632ms/step - loss: 0.1596 - val_loss: 2.1790\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 68s 548ms/step - loss: 0.1544 - val_loss: 2.1820\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 66s 526ms/step - loss: 0.1494 - val_loss: 2.1935\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 66s 525ms/step - loss: 0.1437 - val_loss: 2.1985\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 65s 521ms/step - loss: 0.1387 - val_loss: 2.2075\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 65s 521ms/step - loss: 0.1341 - val_loss: 2.2205\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.1290 - val_loss: 2.2272\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 74s 596ms/step - loss: 0.1243 - val_loss: 2.2407\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 75s 600ms/step - loss: 0.1201 - val_loss: 2.2420\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 0.1153 - val_loss: 2.2538\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 65s 523ms/step - loss: 0.1111 - val_loss: 2.2596\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 66s 525ms/step - loss: 0.1070 - val_loss: 2.2566\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 65s 523ms/step - loss: 0.1028 - val_loss: 2.2805\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 72s 573ms/step - loss: 0.0988 - val_loss: 2.2825\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 71s 569ms/step - loss: 0.0950 - val_loss: 2.2853\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 69s 551ms/step - loss: 0.0923 - val_loss: 2.2987\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 70s 563ms/step - loss: 0.0885 - val_loss: 2.3051\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 72s 579ms/step - loss: 0.0848 - val_loss: 2.3082\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 70s 560ms/step - loss: 0.0820 - val_loss: 2.3279\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 68s 544ms/step - loss: 0.0784 - val_loss: 2.3283\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 66s 532ms/step - loss: 0.0758 - val_loss: 2.3462\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.0725 - val_loss: 2.3478\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 66s 531ms/step - loss: 0.0702 - val_loss: 2.3431\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 66s 525ms/step - loss: 0.0672 - val_loss: 2.3568\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 66s 531ms/step - loss: 0.0634 - val_loss: 2.3684\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 65s 519ms/step - loss: 0.0624 - val_loss: 2.3735\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 66s 532ms/step - loss: 0.0593 - val_loss: 2.3655\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 71s 572ms/step - loss: 0.0572 - val_loss: 2.3796\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 69s 551ms/step - loss: 0.0548 - val_loss: 2.3930\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 0.0526 - val_loss: 2.3980\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 66s 528ms/step - loss: 0.0505 - val_loss: 2.4077\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 65s 517ms/step - loss: 0.0486 - val_loss: 2.4058\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 65s 521ms/step - loss: 0.0462 - val_loss: 2.4285\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 66s 527ms/step - loss: 0.0451 - val_loss: 2.4288\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.0434 - val_loss: 2.4256\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 71s 572ms/step - loss: 0.0417 - val_loss: 2.4359\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 66s 530ms/step - loss: 0.0406 - val_loss: 2.4465\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 66s 530ms/step - loss: 0.0385 - val_loss: 2.4498\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 67s 539ms/step - loss: 0.0371 - val_loss: 2.4589\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 66s 530ms/step - loss: 0.0363 - val_loss: 2.4594\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 65s 520ms/step - loss: 0.0341 - val_loss: 2.4660\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.0332 - val_loss: 2.4738\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 65s 519ms/step - loss: 0.0326 - val_loss: 2.4838\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.0314 - val_loss: 2.4809\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 66s 531ms/step - loss: 0.0305 - val_loss: 2.4832\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 66s 529ms/step - loss: 0.0303 - val_loss: 2.4847\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 65s 524ms/step - loss: 0.0286 - val_loss: 2.4961\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 71s 565ms/step - loss: 0.0277 - val_loss: 2.4995\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 65s 519ms/step - loss: 0.0272 - val_loss: 2.5012\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 65s 522ms/step - loss: 0.0255 - val_loss: 2.5206\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 68s 547ms/step - loss: 0.0256 - val_loss: 2.5071\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 64s 515ms/step - loss: 0.0247 - val_loss: 2.5174\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 66s 531ms/step - loss: 0.0236 - val_loss: 2.5226\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 68s 541ms/step - loss: 0.0235 - val_loss: 2.5277\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 66s 528ms/step - loss: 0.0224 - val_loss: 2.5360\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.0218 - val_loss: 2.5260\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 65s 524ms/step - loss: 0.0212 - val_loss: 2.5432\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 65s 516ms/step - loss: 0.0211 - val_loss: 2.5415\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 65s 516ms/step - loss: 0.0201 - val_loss: 2.5507\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 64s 516ms/step - loss: 0.0194 - val_loss: 2.5553\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.0194 - val_loss: 2.5610\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 64s 516ms/step - loss: 0.0196 - val_loss: 2.5698\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 68s 541ms/step - loss: 0.0185 - val_loss: 2.5644\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 66s 532ms/step - loss: 0.0187 - val_loss: 2.5732\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 0.0179 - val_loss: 2.5864\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 65s 518ms/step - loss: 0.0177 - val_loss: 2.5822\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 66s 526ms/step - loss: 0.0170 - val_loss: 2.5809\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 65s 523ms/step - loss: 0.0171 - val_loss: 2.5946\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 65s 520ms/step - loss: 0.0171 - val_loss: 2.5979\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 64s 515ms/step - loss: 0.0169 - val_loss: 2.6013\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 66s 528ms/step - loss: 0.0162 - val_loss: 2.6079\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 67s 537ms/step - loss: 0.0156 - val_loss: 2.6058\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 67s 533ms/step - loss: 0.0161 - val_loss: 2.6092\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 72s 573ms/step - loss: 0.0150 - val_loss: 2.6102\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 65s 519ms/step - loss: 0.0156 - val_loss: 2.6228\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 64s 516ms/step - loss: 0.0147 - val_loss: 2.6165\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 65s 519ms/step - loss: 0.0148 - val_loss: 2.6177\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 65s 521ms/step - loss: 0.0147 - val_loss: 2.6279\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 66s 527ms/step - loss: 0.0144 - val_loss: 2.6258\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 64s 513ms/step - loss: 0.0146 - val_loss: 2.6285\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 66s 529ms/step - loss: 0.0144 - val_loss: 2.6345\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 68s 547ms/step - loss: 0.0141 - val_loss: 2.6405\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 66s 529ms/step - loss: 0.0136 - val_loss: 2.6457\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - 69s 549ms/step - loss: 0.0140 - val_loss: 2.6326\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 92s 737ms/step - loss: 0.0130 - val_loss: 2.6554\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 67s 534ms/step - loss: 0.0136 - val_loss: 2.6631\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 74s 592ms/step - loss: 0.0132 - val_loss: 2.6635\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 76s 612ms/step - loss: 0.0127 - val_loss: 2.6635\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 78s 624ms/step - loss: 0.0126 - val_loss: 2.6610\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 78s 624ms/step - loss: 0.0129 - val_loss: 2.6570\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 74s 592ms/step - loss: 0.0124 - val_loss: 2.6672\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 72s 575ms/step - loss: 0.0125 - val_loss: 2.6603\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 76s 612ms/step - loss: 0.0125 - val_loss: 2.6745\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 74s 590ms/step - loss: 0.0125 - val_loss: 2.6798\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 90s 720ms/step - loss: 0.0121 - val_loss: 2.6823\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 79s 633ms/step - loss: 0.0123 - val_loss: 2.6914\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 88s 701ms/step - loss: 0.0117 - val_loss: 2.6931\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 82s 656ms/step - loss: 0.0120 - val_loss: 2.7013\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.0121 - val_loss: 2.7015\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 70s 559ms/step - loss: 0.0116 - val_loss: 2.6948\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 74s 595ms/step - loss: 0.0113 - val_loss: 2.6954\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 73s 583ms/step - loss: 0.0116 - val_loss: 2.6958\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 68s 546ms/step - loss: 0.0115 - val_loss: 2.7020\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 67s 534ms/step - loss: 0.0116 - val_loss: 2.7009\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 0.0117 - val_loss: 2.7093\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 72s 577ms/step - loss: 0.0109 - val_loss: 2.7063\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 78s 624ms/step - loss: 0.0109 - val_loss: 2.7172\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 84s 671ms/step - loss: 0.0107 - val_loss: 2.7224\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 78s 625ms/step - loss: 0.0114 - val_loss: 2.7280\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 78s 620ms/step - loss: 0.0105 - val_loss: 2.7229\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 77s 616ms/step - loss: 0.0112 - val_loss: 2.7269\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 77s 615ms/step - loss: 0.0107 - val_loss: 2.7310\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 84s 669ms/step - loss: 0.0107 - val_loss: 2.7164\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 86s 690ms/step - loss: 0.0105 - val_loss: 2.7287\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 79s 636ms/step - loss: 0.0101 - val_loss: 2.7374\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 79s 631ms/step - loss: 0.0106 - val_loss: 2.7392\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 76s 606ms/step - loss: 0.0104 - val_loss: 2.7460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aa9e16beb8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.fit([encoder_input,decoder_input],decoder_output,batch_size=BATCH_SIZE,epochs=EPOCH,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T18:50:37.752537Z",
     "start_time": "2020-11-28T15:09:49.572548Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "141/141 [==============================] - 77s 548ms/step - loss: 0.3128 - val_loss: 2.5693\n",
      "Epoch 2/200\n",
      "141/141 [==============================] - 70s 496ms/step - loss: 0.2362 - val_loss: 2.5166\n",
      "Epoch 3/200\n",
      "141/141 [==============================] - 67s 473ms/step - loss: 0.1868 - val_loss: 2.4991\n",
      "Epoch 4/200\n",
      "141/141 [==============================] - 66s 467ms/step - loss: 0.1590 - val_loss: 2.4950\n",
      "Epoch 5/200\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.1297 - val_loss: 2.4820\n",
      "Epoch 6/200\n",
      "141/141 [==============================] - 66s 470ms/step - loss: 0.1010 - val_loss: 2.4892\n",
      "Epoch 7/200\n",
      "141/141 [==============================] - 73s 516ms/step - loss: 0.0810 - val_loss: 2.4959\n",
      "Epoch 8/200\n",
      "141/141 [==============================] - 83s 590ms/step - loss: 0.0665 - val_loss: 2.5039\n",
      "Epoch 9/200\n",
      "141/141 [==============================] - 89s 628ms/step - loss: 0.0544 - val_loss: 2.5066\n",
      "Epoch 10/200\n",
      "141/141 [==============================] - 91s 645ms/step - loss: 0.0456 - val_loss: 2.5154\n",
      "Epoch 11/200\n",
      "141/141 [==============================] - 92s 654ms/step - loss: 0.0399 - val_loss: 2.5238\n",
      "Epoch 12/200\n",
      "141/141 [==============================] - 77s 549ms/step - loss: 0.0372 - val_loss: 2.5358\n",
      "Epoch 13/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0331 - val_loss: 2.5437\n",
      "Epoch 14/200\n",
      "141/141 [==============================] - 66s 465ms/step - loss: 0.0305 - val_loss: 2.5533\n",
      "Epoch 15/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0283 - val_loss: 2.5585\n",
      "Epoch 16/200\n",
      "141/141 [==============================] - 70s 497ms/step - loss: 0.0273 - val_loss: 2.5672\n",
      "Epoch 17/200\n",
      "141/141 [==============================] - 66s 465ms/step - loss: 0.0257 - val_loss: 2.5780\n",
      "Epoch 18/200\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0244 - val_loss: 2.5833\n",
      "Epoch 19/200\n",
      "141/141 [==============================] - 66s 468ms/step - loss: 0.0233 - val_loss: 2.5938\n",
      "Epoch 20/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0230 - val_loss: 2.5955\n",
      "Epoch 21/200\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0233 - val_loss: 2.6039\n",
      "Epoch 22/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0996 - val_loss: 2.5969\n",
      "Epoch 23/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.1315 - val_loss: 2.5547\n",
      "Epoch 24/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0609 - val_loss: 2.5535\n",
      "Epoch 25/200\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0350 - val_loss: 2.5577\n",
      "Epoch 26/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0254 - val_loss: 2.5666\n",
      "Epoch 27/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0215 - val_loss: 2.5808\n",
      "Epoch 28/200\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0201 - val_loss: 2.5825\n",
      "Epoch 29/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0194 - val_loss: 2.5895\n",
      "Epoch 30/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0190 - val_loss: 2.5933\n",
      "Epoch 31/200\n",
      "141/141 [==============================] - 65s 464ms/step - loss: 0.0188 - val_loss: 2.5995\n",
      "Epoch 32/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0187 - val_loss: 2.6049\n",
      "Epoch 33/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0185 - val_loss: 2.6096\n",
      "Epoch 34/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0183 - val_loss: 2.6141\n",
      "Epoch 35/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0186 - val_loss: 2.6191\n",
      "Epoch 36/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0186 - val_loss: 2.6229\n",
      "Epoch 37/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0185 - val_loss: 2.6252\n",
      "Epoch 38/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0186 - val_loss: 2.6350\n",
      "Epoch 39/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0187 - val_loss: 2.6364\n",
      "Epoch 40/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0184 - val_loss: 2.6454\n",
      "Epoch 41/200\n",
      "141/141 [==============================] - 65s 457ms/step - loss: 0.0190 - val_loss: 2.6449\n",
      "Epoch 42/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0193 - val_loss: 2.6511\n",
      "Epoch 43/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0534 - val_loss: 2.6625\n",
      "Epoch 44/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.1927 - val_loss: 2.5828\n",
      "Epoch 45/200\n",
      "141/141 [==============================] - 66s 469ms/step - loss: 0.0736 - val_loss: 2.5746\n",
      "Epoch 46/200\n",
      "141/141 [==============================] - 66s 466ms/step - loss: 0.0338 - val_loss: 2.5785\n",
      "Epoch 47/200\n",
      "141/141 [==============================] - 69s 487ms/step - loss: 0.0223 - val_loss: 2.5910\n",
      "Epoch 48/200\n",
      "141/141 [==============================] - 68s 484ms/step - loss: 0.0192 - val_loss: 2.6020\n",
      "Epoch 49/200\n",
      "141/141 [==============================] - 68s 481ms/step - loss: 0.0181 - val_loss: 2.6084\n",
      "Epoch 50/200\n",
      "141/141 [==============================] - 68s 479ms/step - loss: 0.0174 - val_loss: 2.6144\n",
      "Epoch 51/200\n",
      "141/141 [==============================] - 67s 475ms/step - loss: 0.0171 - val_loss: 2.6184\n",
      "Epoch 52/200\n",
      "141/141 [==============================] - 69s 491ms/step - loss: 0.0169 - val_loss: 2.6267\n",
      "Epoch 53/200\n",
      "141/141 [==============================] - 66s 465ms/step - loss: 0.0168 - val_loss: 2.6281\n",
      "Epoch 54/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0167 - val_loss: 2.6354\n",
      "Epoch 55/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0166 - val_loss: 2.6393\n",
      "Epoch 56/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0166 - val_loss: 2.6457\n",
      "Epoch 57/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0166 - val_loss: 2.6494\n",
      "Epoch 58/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0166 - val_loss: 2.6510\n",
      "Epoch 59/200\n",
      "141/141 [==============================] - 66s 466ms/step - loss: 0.0167 - val_loss: 2.6501\n",
      "Epoch 60/200\n",
      "141/141 [==============================] - 66s 466ms/step - loss: 0.0168 - val_loss: 2.6561\n",
      "Epoch 61/200\n",
      "141/141 [==============================] - 67s 473ms/step - loss: 0.0166 - val_loss: 2.6605\n",
      "Epoch 62/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0167 - val_loss: 2.6610\n",
      "Epoch 63/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0170 - val_loss: 2.6671\n",
      "Epoch 64/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0177 - val_loss: 2.6712\n",
      "Epoch 65/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0867 - val_loss: 2.6417\n",
      "Epoch 66/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.1394 - val_loss: 2.6290\n",
      "Epoch 67/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0493 - val_loss: 2.6255\n",
      "Epoch 68/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0252 - val_loss: 2.6342\n",
      "Epoch 69/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0188 - val_loss: 2.6392\n",
      "Epoch 70/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0167 - val_loss: 2.6465\n",
      "Epoch 71/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0160 - val_loss: 2.6541\n",
      "Epoch 72/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0158 - val_loss: 2.6609\n",
      "Epoch 73/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0155 - val_loss: 2.6641\n",
      "Epoch 74/200\n",
      "141/141 [==============================] - 68s 483ms/step - loss: 0.0154 - val_loss: 2.6725\n",
      "Epoch 75/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0154 - val_loss: 2.6695\n",
      "Epoch 76/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0152 - val_loss: 2.6784\n",
      "Epoch 77/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0153 - val_loss: 2.6798\n",
      "Epoch 78/200\n",
      "141/141 [==============================] - 70s 497ms/step - loss: 0.0152 - val_loss: 2.6818\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 66s 471ms/step - loss: 0.0154 - val_loss: 2.6890\n",
      "Epoch 80/200\n",
      "141/141 [==============================] - 66s 469ms/step - loss: 0.0154 - val_loss: 2.6918\n",
      "Epoch 81/200\n",
      "141/141 [==============================] - 66s 469ms/step - loss: 0.0154 - val_loss: 2.6950\n",
      "Epoch 82/200\n",
      "141/141 [==============================] - 65s 464ms/step - loss: 0.0153 - val_loss: 2.7000\n",
      "Epoch 83/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0155 - val_loss: 2.6964\n",
      "Epoch 84/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0156 - val_loss: 2.7036\n",
      "Epoch 85/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0158 - val_loss: 2.7059\n",
      "Epoch 86/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0159 - val_loss: 2.7104\n",
      "Epoch 87/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0162 - val_loss: 2.7020\n",
      "Epoch 88/200\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0436 - val_loss: 2.7136\n",
      "Epoch 89/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.1465 - val_loss: 2.6535\n",
      "Epoch 90/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0567 - val_loss: 2.6407\n",
      "Epoch 91/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0257 - val_loss: 2.6507\n",
      "Epoch 92/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0182 - val_loss: 2.6542\n",
      "Epoch 93/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0159 - val_loss: 2.6606\n",
      "Epoch 94/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0152 - val_loss: 2.6651\n",
      "Epoch 95/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0149 - val_loss: 2.6702\n",
      "Epoch 96/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0147 - val_loss: 2.6777\n",
      "Epoch 97/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0145 - val_loss: 2.6799\n",
      "Epoch 98/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0145 - val_loss: 2.6835\n",
      "Epoch 99/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0144 - val_loss: 2.6876\n",
      "Epoch 100/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0144 - val_loss: 2.6910\n",
      "Epoch 101/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0145 - val_loss: 2.6977\n",
      "Epoch 102/200\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0145 - val_loss: 2.7011\n",
      "Epoch 103/200\n",
      "141/141 [==============================] - 65s 464ms/step - loss: 0.0145 - val_loss: 2.7055\n",
      "Epoch 104/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0144 - val_loss: 2.7053\n",
      "Epoch 105/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0146 - val_loss: 2.7096\n",
      "Epoch 106/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0147 - val_loss: 2.7088\n",
      "Epoch 107/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0147 - val_loss: 2.7069\n",
      "Epoch 108/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0148 - val_loss: 2.7198\n",
      "Epoch 109/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0149 - val_loss: 2.7170\n",
      "Epoch 110/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0153 - val_loss: 2.7223\n",
      "Epoch 111/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0245 - val_loss: 2.7178\n",
      "Epoch 112/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.1263 - val_loss: 2.6771\n",
      "Epoch 113/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0673 - val_loss: 2.6661\n",
      "Epoch 114/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0277 - val_loss: 2.6635\n",
      "Epoch 115/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0180 - val_loss: 2.6679\n",
      "Epoch 116/200\n",
      "141/141 [==============================] - 66s 471ms/step - loss: 0.0155 - val_loss: 2.6726\n",
      "Epoch 117/200\n",
      "141/141 [==============================] - 66s 466ms/step - loss: 0.0147 - val_loss: 2.6785\n",
      "Epoch 118/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0144 - val_loss: 2.6820\n",
      "Epoch 119/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0142 - val_loss: 2.6881\n",
      "Epoch 120/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0141 - val_loss: 2.6916\n",
      "Epoch 121/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0141 - val_loss: 2.6957\n",
      "Epoch 122/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0141 - val_loss: 2.6952\n",
      "Epoch 123/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0140 - val_loss: 2.7003\n",
      "Epoch 124/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0140 - val_loss: 2.7023\n",
      "Epoch 125/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0141 - val_loss: 2.7067\n",
      "Epoch 126/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0142 - val_loss: 2.7086\n",
      "Epoch 127/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0141 - val_loss: 2.7083\n",
      "Epoch 128/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0142 - val_loss: 2.7122\n",
      "Epoch 129/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0144 - val_loss: 2.7137\n",
      "Epoch 130/200\n",
      "141/141 [==============================] - 67s 476ms/step - loss: 0.0143 - val_loss: 2.7179\n",
      "Epoch 131/200\n",
      "141/141 [==============================] - 66s 470ms/step - loss: 0.0145 - val_loss: 2.7164\n",
      "Epoch 132/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0144 - val_loss: 2.7230\n",
      "Epoch 133/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0146 - val_loss: 2.7287\n",
      "Epoch 134/200\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0203 - val_loss: 2.7469\n",
      "Epoch 135/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.1190 - val_loss: 2.6868\n",
      "Epoch 136/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0660 - val_loss: 2.6868\n",
      "Epoch 137/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0281 - val_loss: 2.6951\n",
      "Epoch 138/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0186 - val_loss: 2.6980\n",
      "Epoch 139/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0154 - val_loss: 2.6988\n",
      "Epoch 140/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0143 - val_loss: 2.7021\n",
      "Epoch 141/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0137 - val_loss: 2.7099\n",
      "Epoch 142/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0136 - val_loss: 2.7118\n",
      "Epoch 143/200\n",
      "141/141 [==============================] - 65s 457ms/step - loss: 0.0134 - val_loss: 2.7169\n",
      "Epoch 144/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0134 - val_loss: 2.7185\n",
      "Epoch 145/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0134 - val_loss: 2.7219\n",
      "Epoch 146/200\n",
      "141/141 [==============================] - 66s 466ms/step - loss: 0.0134 - val_loss: 2.7239\n",
      "Epoch 147/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0133 - val_loss: 2.7274\n",
      "Epoch 148/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0134 - val_loss: 2.7335\n",
      "Epoch 149/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0135 - val_loss: 2.7317\n",
      "Epoch 150/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0135 - val_loss: 2.7372\n",
      "Epoch 151/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0136 - val_loss: 2.7371\n",
      "Epoch 152/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0135 - val_loss: 2.7427\n",
      "Epoch 153/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0135 - val_loss: 2.7398\n",
      "Epoch 154/200\n",
      "141/141 [==============================] - 66s 465ms/step - loss: 0.0142 - val_loss: 2.7460\n",
      "Epoch 155/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0146 - val_loss: 2.7425\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0220 - val_loss: 2.7403\n",
      "Epoch 157/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0915 - val_loss: 2.7005\n",
      "Epoch 158/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0589 - val_loss: 2.7074\n",
      "Epoch 159/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0254 - val_loss: 2.7125\n",
      "Epoch 160/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0168 - val_loss: 2.7213\n",
      "Epoch 161/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0144 - val_loss: 2.7277\n",
      "Epoch 162/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0139 - val_loss: 2.7295\n",
      "Epoch 163/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0134 - val_loss: 2.7363\n",
      "Epoch 164/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0135 - val_loss: 2.7394\n",
      "Epoch 165/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0133 - val_loss: 2.7393\n",
      "Epoch 166/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0132 - val_loss: 2.7413\n",
      "Epoch 167/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0132 - val_loss: 2.7455\n",
      "Epoch 168/200\n",
      "141/141 [==============================] - 64s 453ms/step - loss: 0.0132 - val_loss: 2.7475\n",
      "Epoch 169/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0132 - val_loss: 2.7532\n",
      "Epoch 170/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0131 - val_loss: 2.7510\n",
      "Epoch 171/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0132 - val_loss: 2.7551\n",
      "Epoch 172/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0133 - val_loss: 2.7548\n",
      "Epoch 173/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0134 - val_loss: 2.7602\n",
      "Epoch 174/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0134 - val_loss: 2.7587\n",
      "Epoch 175/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0134 - val_loss: 2.7644\n",
      "Epoch 176/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0135 - val_loss: 2.7640\n",
      "Epoch 177/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0137 - val_loss: 2.7648\n",
      "Epoch 178/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0137 - val_loss: 2.7682\n",
      "Epoch 179/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0138 - val_loss: 2.7683\n",
      "Epoch 180/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0141 - val_loss: 2.7710\n",
      "Epoch 181/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0234 - val_loss: 2.7628\n",
      "Epoch 182/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.1114 - val_loss: 2.7135\n",
      "Epoch 183/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0491 - val_loss: 2.7234\n",
      "Epoch 184/200\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0232 - val_loss: 2.7084\n",
      "Epoch 185/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0159 - val_loss: 2.7226\n",
      "Epoch 186/200\n",
      "141/141 [==============================] - 65s 459ms/step - loss: 0.0142 - val_loss: 2.7300\n",
      "Epoch 187/200\n",
      "141/141 [==============================] - 64s 456ms/step - loss: 0.0133 - val_loss: 2.7321\n",
      "Epoch 188/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0131 - val_loss: 2.7388\n",
      "Epoch 189/200\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0129 - val_loss: 2.7415\n",
      "Epoch 190/200\n",
      "141/141 [==============================] - 66s 465ms/step - loss: 0.0128 - val_loss: 2.7478\n",
      "Epoch 191/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0128 - val_loss: 2.7508\n",
      "Epoch 192/200\n",
      "141/141 [==============================] - 69s 487ms/step - loss: 0.0127 - val_loss: 2.7497\n",
      "Epoch 193/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0127 - val_loss: 2.7546\n",
      "Epoch 194/200\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0128 - val_loss: 2.7587\n",
      "Epoch 195/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0128 - val_loss: 2.7582\n",
      "Epoch 196/200\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0129 - val_loss: 2.7611\n",
      "Epoch 197/200\n",
      "141/141 [==============================] - 64s 453ms/step - loss: 0.0129 - val_loss: 2.7656\n",
      "Epoch 198/200\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0129 - val_loss: 2.7655\n",
      "Epoch 199/200\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0130 - val_loss: 2.7658\n",
      "Epoch 200/200\n",
      "141/141 [==============================] - 64s 452ms/step - loss: 0.0131 - val_loss: 2.7701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aaa027eb00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.fit([encoder_input,decoder_input],decoder_output,batch_size=BATCH_SIZE,epochs=EPOCH,validation_split=0.1,verbose = 1)\n",
    "#改了EPOCH VALIDATIONSPLIT ADAM 之后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:11:46.998312Z",
     "start_time": "2020-11-30T00:19:22.963335Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n",
      "141/141 [==============================] - 91s 643ms/step - loss: 0.0187 - val_loss: 2.7723\n",
      "Epoch 2/140\n",
      "141/141 [==============================] - 76s 539ms/step - loss: 0.0206 - val_loss: 2.7615\n",
      "Epoch 3/140\n",
      "141/141 [==============================] - 72s 513ms/step - loss: 0.0186 - val_loss: 2.7640\n",
      "Epoch 4/140\n",
      "141/141 [==============================] - 72s 508ms/step - loss: 0.0171 - val_loss: 2.7553\n",
      "Epoch 5/140\n",
      "141/141 [==============================] - 72s 513ms/step - loss: 0.0152 - val_loss: 2.7654\n",
      "Epoch 6/140\n",
      "141/141 [==============================] - 78s 551ms/step - loss: 0.0144 - val_loss: 2.7739\n",
      "Epoch 7/140\n",
      "141/141 [==============================] - 76s 538ms/step - loss: 0.0137 - val_loss: 2.7705\n",
      "Epoch 8/140\n",
      "141/141 [==============================] - 77s 548ms/step - loss: 0.0143 - val_loss: 2.7812\n",
      "Epoch 9/140\n",
      "141/141 [==============================] - 80s 565ms/step - loss: 0.0180 - val_loss: 2.7782\n",
      "Epoch 10/140\n",
      "141/141 [==============================] - 81s 573ms/step - loss: 0.0210 - val_loss: 2.7758\n",
      "Epoch 11/140\n",
      "141/141 [==============================] - 80s 567ms/step - loss: 0.0229 - val_loss: 2.7692\n",
      "Epoch 12/140\n",
      "141/141 [==============================] - 77s 546ms/step - loss: 0.0251 - val_loss: 2.7606\n",
      "Epoch 13/140\n",
      "141/141 [==============================] - 77s 543ms/step - loss: 0.0226 - val_loss: 2.7693\n",
      "Epoch 14/140\n",
      "141/141 [==============================] - 81s 577ms/step - loss: 0.0178 - val_loss: 2.7671\n",
      "Epoch 15/140\n",
      "141/141 [==============================] - 78s 556ms/step - loss: 0.0153 - val_loss: 2.7703\n",
      "Epoch 16/140\n",
      "141/141 [==============================] - 82s 581ms/step - loss: 0.0141 - val_loss: 2.7767\n",
      "Epoch 17/140\n",
      "141/141 [==============================] - 77s 545ms/step - loss: 0.0135 - val_loss: 2.7731\n",
      "Epoch 18/140\n",
      "141/141 [==============================] - 80s 566ms/step - loss: 0.0130 - val_loss: 2.7769\n",
      "Epoch 19/140\n",
      "141/141 [==============================] - 77s 546ms/step - loss: 0.0130 - val_loss: 2.7819\n",
      "Epoch 20/140\n",
      "141/141 [==============================] - 82s 580ms/step - loss: 0.0127 - val_loss: 2.7839\n",
      "Epoch 21/140\n",
      "141/141 [==============================] - 80s 566ms/step - loss: 0.0128 - val_loss: 2.7892\n",
      "Epoch 22/140\n",
      "141/141 [==============================] - 77s 548ms/step - loss: 0.0127 - val_loss: 2.7894\n",
      "Epoch 23/140\n",
      "141/141 [==============================] - 77s 546ms/step - loss: 0.0128 - val_loss: 2.7888\n",
      "Epoch 24/140\n",
      "141/141 [==============================] - 73s 518ms/step - loss: 0.0128 - val_loss: 2.7933\n",
      "Epoch 25/140\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0129 - val_loss: 2.7933\n",
      "Epoch 26/140\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0129 - val_loss: 2.7912\n",
      "Epoch 27/140\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0130 - val_loss: 2.7969\n",
      "Epoch 28/140\n",
      "141/141 [==============================] - 67s 472ms/step - loss: 0.0132 - val_loss: 2.7970\n",
      "Epoch 29/140\n",
      "141/141 [==============================] - 77s 543ms/step - loss: 0.0359 - val_loss: 2.8085\n",
      "Epoch 30/140\n",
      "141/141 [==============================] - 78s 557ms/step - loss: 0.0828 - val_loss: 2.7761\n",
      "Epoch 31/140\n",
      "141/141 [==============================] - 79s 558ms/step - loss: 0.0376 - val_loss: 2.7730\n",
      "Epoch 32/140\n",
      "141/141 [==============================] - 74s 527ms/step - loss: 0.0186 - val_loss: 2.7613\n",
      "Epoch 33/140\n",
      "141/141 [==============================] - 71s 507ms/step - loss: 0.0142 - val_loss: 2.7620\n",
      "Epoch 34/140\n",
      "141/141 [==============================] - 69s 486ms/step - loss: 0.0128 - val_loss: 2.7739\n",
      "Epoch 35/140\n",
      "141/141 [==============================] - 73s 518ms/step - loss: 0.0123 - val_loss: 2.7744\n",
      "Epoch 36/140\n",
      "141/141 [==============================] - 68s 481ms/step - loss: 0.0122 - val_loss: 2.7802\n",
      "Epoch 37/140\n",
      "141/141 [==============================] - 69s 492ms/step - loss: 0.0121 - val_loss: 2.7765\n",
      "Epoch 38/140\n",
      "141/141 [==============================] - 76s 536ms/step - loss: 0.0121 - val_loss: 2.7827\n",
      "Epoch 39/140\n",
      "141/141 [==============================] - 71s 507ms/step - loss: 0.0120 - val_loss: 2.7861\n",
      "Epoch 40/140\n",
      "141/141 [==============================] - 69s 491ms/step - loss: 0.0120 - val_loss: 2.7884\n",
      "Epoch 41/140\n",
      "141/141 [==============================] - 68s 484ms/step - loss: 0.0121 - val_loss: 2.7888\n",
      "Epoch 42/140\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0121 - val_loss: 2.7933\n",
      "Epoch 43/140\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0121 - val_loss: 2.7921\n",
      "Epoch 44/140\n",
      "141/141 [==============================] - 64s 457ms/step - loss: 0.0121 - val_loss: 2.7966\n",
      "Epoch 45/140\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0122 - val_loss: 2.7991\n",
      "Epoch 46/140\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0122 - val_loss: 2.8011\n",
      "Epoch 47/140\n",
      "141/141 [==============================] - 65s 463ms/step - loss: 0.0123 - val_loss: 2.8000\n",
      "Epoch 48/140\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0122 - val_loss: 2.8082\n",
      "Epoch 49/140\n",
      "141/141 [==============================] - 68s 484ms/step - loss: 0.0126 - val_loss: 2.8048\n",
      "Epoch 50/140\n",
      "141/141 [==============================] - 69s 492ms/step - loss: 0.0124 - val_loss: 2.8054\n",
      "Epoch 51/140\n",
      "141/141 [==============================] - 66s 470ms/step - loss: 0.0125 - val_loss: 2.8073\n",
      "Epoch 52/140\n",
      "141/141 [==============================] - 75s 533ms/step - loss: 0.0126 - val_loss: 2.8143\n",
      "Epoch 53/140\n",
      "141/141 [==============================] - 85s 601ms/step - loss: 0.0174 - val_loss: 2.8160\n",
      "Epoch 54/140\n",
      "141/141 [==============================] - 72s 510ms/step - loss: 0.0848 - val_loss: 2.8003\n",
      "Epoch 55/140\n",
      "141/141 [==============================] - 71s 504ms/step - loss: 0.0517 - val_loss: 2.7644\n",
      "Epoch 56/140\n",
      "141/141 [==============================] - 69s 492ms/step - loss: 0.0222 - val_loss: 2.7693\n",
      "Epoch 57/140\n",
      "141/141 [==============================] - 68s 482ms/step - loss: 0.0151 - val_loss: 2.7738\n",
      "Epoch 58/140\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0128 - val_loss: 2.7842\n",
      "Epoch 59/140\n",
      "141/141 [==============================] - 71s 505ms/step - loss: 0.0122 - val_loss: 2.7891\n",
      "Epoch 60/140\n",
      "141/141 [==============================] - 74s 522ms/step - loss: 0.0120 - val_loss: 2.7926\n",
      "Epoch 61/140\n",
      "141/141 [==============================] - 75s 530ms/step - loss: 0.0119 - val_loss: 2.7954\n",
      "Epoch 62/140\n",
      "141/141 [==============================] - 76s 536ms/step - loss: 0.0118 - val_loss: 2.8002\n",
      "Epoch 63/140\n",
      "141/141 [==============================] - 69s 486ms/step - loss: 0.0118 - val_loss: 2.7991\n",
      "Epoch 64/140\n",
      "141/141 [==============================] - 67s 477ms/step - loss: 0.0119 - val_loss: 2.8026\n",
      "Epoch 65/140\n",
      "141/141 [==============================] - 67s 478ms/step - loss: 0.0119 - val_loss: 2.8042\n",
      "Epoch 66/140\n",
      "141/141 [==============================] - 67s 476ms/step - loss: 0.0118 - val_loss: 2.8102\n",
      "Epoch 67/140\n",
      "141/141 [==============================] - 65s 462ms/step - loss: 0.0120 - val_loss: 2.8102\n",
      "Epoch 68/140\n",
      "141/141 [==============================] - 65s 458ms/step - loss: 0.0119 - val_loss: 2.8103\n",
      "Epoch 69/140\n",
      "141/141 [==============================] - 66s 468ms/step - loss: 0.0121 - val_loss: 2.8138\n",
      "Epoch 70/140\n",
      "141/141 [==============================] - 71s 504ms/step - loss: 0.0120 - val_loss: 2.8160\n",
      "Epoch 71/140\n",
      "141/141 [==============================] - 73s 521ms/step - loss: 0.0121 - val_loss: 2.8139\n",
      "Epoch 72/140\n",
      "141/141 [==============================] - 78s 554ms/step - loss: 0.0120 - val_loss: 2.8181\n",
      "Epoch 73/140\n",
      "141/141 [==============================] - 86s 607ms/step - loss: 0.0121 - val_loss: 2.8245\n",
      "Epoch 74/140\n",
      "141/141 [==============================] - 76s 536ms/step - loss: 0.0122 - val_loss: 2.8232\n",
      "Epoch 75/140\n",
      "141/141 [==============================] - 75s 534ms/step - loss: 0.0122 - val_loss: 2.8222\n",
      "Epoch 76/140\n",
      "141/141 [==============================] - 78s 555ms/step - loss: 0.0122 - val_loss: 2.8272\n",
      "Epoch 77/140\n",
      "141/141 [==============================] - 78s 556ms/step - loss: 0.0124 - val_loss: 2.8279\n",
      "Epoch 78/140\n",
      "141/141 [==============================] - 82s 579ms/step - loss: 0.0124 - val_loss: 2.8283\n",
      "Epoch 79/140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 76s 538ms/step - loss: 0.0128 - val_loss: 2.8309\n",
      "Epoch 80/140\n",
      "141/141 [==============================] - 74s 524ms/step - loss: 0.0148 - val_loss: 2.8257\n",
      "Epoch 81/140\n",
      "141/141 [==============================] - 87s 619ms/step - loss: 0.0892 - val_loss: 2.8042\n",
      "Epoch 82/140\n",
      "141/141 [==============================] - 77s 549ms/step - loss: 0.0565 - val_loss: 2.7798\n",
      "Epoch 83/140\n",
      "141/141 [==============================] - 73s 519ms/step - loss: 0.0237 - val_loss: 2.7790\n",
      "Epoch 84/140\n",
      "141/141 [==============================] - 78s 550ms/step - loss: 0.0148 - val_loss: 2.7852\n",
      "Epoch 85/140\n",
      "141/141 [==============================] - 77s 547ms/step - loss: 0.0126 - val_loss: 2.7867\n",
      "Epoch 86/140\n",
      "141/141 [==============================] - 72s 510ms/step - loss: 0.0120 - val_loss: 2.7913\n",
      "Epoch 87/140\n",
      "141/141 [==============================] - 72s 508ms/step - loss: 0.0119 - val_loss: 2.7943\n",
      "Epoch 88/140\n",
      "141/141 [==============================] - 69s 491ms/step - loss: 0.0118 - val_loss: 2.7994\n",
      "Epoch 89/140\n",
      "141/141 [==============================] - 72s 511ms/step - loss: 0.0117 - val_loss: 2.8007\n",
      "Epoch 90/140\n",
      "141/141 [==============================] - 70s 496ms/step - loss: 0.0117 - val_loss: 2.8046\n",
      "Epoch 91/140\n",
      "141/141 [==============================] - 67s 473ms/step - loss: 0.0117 - val_loss: 2.8065\n",
      "Epoch 92/140\n",
      "141/141 [==============================] - 68s 480ms/step - loss: 0.0117 - val_loss: 2.8067\n",
      "Epoch 93/140\n",
      "141/141 [==============================] - 65s 461ms/step - loss: 0.0117 - val_loss: 2.8118\n",
      "Epoch 94/140\n",
      "141/141 [==============================] - 64s 455ms/step - loss: 0.0117 - val_loss: 2.8126\n",
      "Epoch 95/140\n",
      "141/141 [==============================] - 69s 488ms/step - loss: 0.0117 - val_loss: 2.8167\n",
      "Epoch 96/140\n",
      "141/141 [==============================] - 66s 469ms/step - loss: 0.0118 - val_loss: 2.8163\n",
      "Epoch 97/140\n",
      "141/141 [==============================] - 71s 504ms/step - loss: 0.0118 - val_loss: 2.8200\n",
      "Epoch 98/140\n",
      "141/141 [==============================] - 68s 483ms/step - loss: 0.0118 - val_loss: 2.8222\n",
      "Epoch 99/140\n",
      "141/141 [==============================] - 70s 500ms/step - loss: 0.0118 - val_loss: 2.8233\n",
      "Epoch 100/140\n",
      "141/141 [==============================] - 65s 460ms/step - loss: 0.0119 - val_loss: 2.8223\n",
      "Epoch 101/140\n",
      "141/141 [==============================] - 68s 479ms/step - loss: 0.0119 - val_loss: 2.8264\n",
      "Epoch 102/140\n",
      "141/141 [==============================] - 71s 501ms/step - loss: 0.0120 - val_loss: 2.8300\n",
      "Epoch 103/140\n",
      "141/141 [==============================] - 71s 505ms/step - loss: 0.0120 - val_loss: 2.8296\n",
      "Epoch 104/140\n",
      "141/141 [==============================] - 74s 524ms/step - loss: 0.0121 - val_loss: 2.8352\n",
      "Epoch 105/140\n",
      "141/141 [==============================] - 72s 511ms/step - loss: 0.0125 - val_loss: 2.8320\n",
      "Epoch 106/140\n",
      "141/141 [==============================] - 67s 474ms/step - loss: 0.0272 - val_loss: 2.8490\n",
      "Epoch 107/140\n",
      "141/141 [==============================] - 73s 520ms/step - loss: 0.0882 - val_loss: 2.8005\n",
      "Epoch 108/140\n",
      "141/141 [==============================] - 70s 495ms/step - loss: 0.0401 - val_loss: 2.8099\n",
      "Epoch 109/140\n",
      "141/141 [==============================] - 69s 487ms/step - loss: 0.0195 - val_loss: 2.8106\n",
      "Epoch 110/140\n",
      "141/141 [==============================] - 72s 510ms/step - loss: 0.0137 - val_loss: 2.8116\n",
      "Epoch 111/140\n",
      "141/141 [==============================] - 70s 497ms/step - loss: 0.0123 - val_loss: 2.8149\n",
      "Epoch 112/140\n",
      "141/141 [==============================] - 68s 480ms/step - loss: 0.0119 - val_loss: 2.8203\n",
      "Epoch 113/140\n",
      "141/141 [==============================] - 70s 497ms/step - loss: 0.0116 - val_loss: 2.8224\n",
      "Epoch 114/140\n",
      "141/141 [==============================] - 67s 472ms/step - loss: 0.0116 - val_loss: 2.8258\n",
      "Epoch 115/140\n",
      "141/141 [==============================] - 64s 453ms/step - loss: 0.0115 - val_loss: 2.8295\n",
      "Epoch 116/140\n",
      "141/141 [==============================] - 68s 482ms/step - loss: 0.0114 - val_loss: 2.8327\n",
      "Epoch 117/140\n",
      "141/141 [==============================] - 71s 505ms/step - loss: 0.0114 - val_loss: 2.8324\n",
      "Epoch 118/140\n",
      "141/141 [==============================] - 73s 517ms/step - loss: 0.0114 - val_loss: 2.8359\n",
      "Epoch 119/140\n",
      "141/141 [==============================] - 65s 465ms/step - loss: 0.0114 - val_loss: 2.8358\n",
      "Epoch 120/140\n",
      "141/141 [==============================] - 64s 454ms/step - loss: 0.0115 - val_loss: 2.8404\n",
      "Epoch 121/140\n",
      "141/141 [==============================] - 67s 478ms/step - loss: 0.0115 - val_loss: 2.8387\n",
      "Epoch 122/140\n",
      "141/141 [==============================] - 67s 472ms/step - loss: 0.0115 - val_loss: 2.8411\n",
      "Epoch 123/140\n",
      "141/141 [==============================] - 67s 472ms/step - loss: 0.0116 - val_loss: 2.8465\n",
      "Epoch 124/140\n",
      "141/141 [==============================] - 69s 487ms/step - loss: 0.0116 - val_loss: 2.8446\n",
      "Epoch 125/140\n",
      "141/141 [==============================] - 68s 485ms/step - loss: 0.0116 - val_loss: 2.8463\n",
      "Epoch 126/140\n",
      "141/141 [==============================] - 73s 515ms/step - loss: 0.0116 - val_loss: 2.8474\n",
      "Epoch 127/140\n",
      "141/141 [==============================] - 78s 553ms/step - loss: 0.0117 - val_loss: 2.8473\n",
      "Epoch 128/140\n",
      "141/141 [==============================] - 85s 604ms/step - loss: 0.0117 - val_loss: 2.8507\n",
      "Epoch 129/140\n",
      "141/141 [==============================] - 92s 651ms/step - loss: 0.0118 - val_loss: 2.8503\n",
      "Epoch 130/140\n",
      "141/141 [==============================] - 84s 599ms/step - loss: 0.0120 - val_loss: 2.8518\n",
      "Epoch 131/140\n",
      "141/141 [==============================] - 82s 584ms/step - loss: 0.0119 - val_loss: 2.8519\n",
      "Epoch 132/140\n",
      "141/141 [==============================] - 80s 568ms/step - loss: 0.0125 - val_loss: 2.8420\n",
      "Epoch 133/140\n",
      "141/141 [==============================] - 80s 564ms/step - loss: 0.0413 - val_loss: 2.8546\n",
      "Epoch 134/140\n",
      "141/141 [==============================] - 84s 595ms/step - loss: 0.0822 - val_loss: 2.8185\n",
      "Epoch 135/140\n",
      "141/141 [==============================] - 87s 616ms/step - loss: 0.0304 - val_loss: 2.8080\n",
      "Epoch 136/140\n",
      "141/141 [==============================] - 86s 610ms/step - loss: 0.0161 - val_loss: 2.8140\n",
      "Epoch 137/140\n",
      "141/141 [==============================] - 83s 586ms/step - loss: 0.0127 - val_loss: 2.8164\n",
      "Epoch 138/140\n",
      "141/141 [==============================] - 85s 601ms/step - loss: 0.0117 - val_loss: 2.8181\n",
      "Epoch 139/140\n",
      "141/141 [==============================] - 83s 588ms/step - loss: 0.0115 - val_loss: 2.8244\n",
      "Epoch 140/140\n",
      "141/141 [==============================] - 83s 586ms/step - loss: 0.0113 - val_loss: 2.8257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2aaa08caac8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.fit([encoder_input,decoder_input],decoder_output,batch_size=BATCH_SIZE,epochs=EPOCH,validation_split=0.1,verbose = 1)\n",
    "#改了EPOCH VALIDATIONSPLIT ADAM 之后"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T11:13:52.046410Z",
     "start_time": "2020-11-20T11:13:52.019516Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_chinese(source,encoder_inference, decoder_inference, n_steps, features):\n",
    "    #先通过推理encoder获得预测输入序列的隐状态\n",
    "    state = encoder_inference.predict(source)\n",
    "    #第一个字符'\\t',为起始标志\n",
    "    predict_seq = np.zeros((1,1,features))\n",
    "    predict_seq[0,0,target_dict['\\t']] = 1\n",
    "\n",
    "    output = ''\n",
    "    #开始对encoder获得的隐状态进行推理\n",
    "    #每次循环用上次预测的字符作为输入来预测下一次的字符，直到预测出了终止符\n",
    "    for i in range(n_steps):#n_steps为句子最大长度\n",
    "        #给decoder输入上一个时刻的h,c隐状态，以及上一次的预测字符predict_seq\n",
    "        yhat,h,c = decoder_inference.predict([predict_seq]+state)\n",
    "        #注意，这里的yhat为Dense之后输出的结果，因此与h不同\n",
    "        char_index = np.argmax(yhat[0,-1,:])\n",
    "        char = target_dict_reverse[char_index]\n",
    "        output += char\n",
    "        state = [h,c]#本次状态做为下一次的初始状态继续传递\n",
    "        predict_seq = np.zeros((1,1,features))\n",
    "        predict_seq[0,0,char_index] = 1\n",
    "        if char == '\\n':#预测到了终止符则停下来\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T11:14:56.313542Z",
     "start_time": "2020-11-20T11:14:01.316135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have brothers.\n",
      "我有兄弟。\n",
      "\n",
      "I have ten pens.\n",
      "我有十支筆。\n",
      "\n",
      "I have to hurry!\n",
      "我要赶紧了!\n",
      "\n",
      "I have two cats.\n",
      "我有两只猫。\n",
      "\n",
      "I have two sons.\n",
      "我有兩個兒子。\n",
      "\n",
      "I just threw up.\n",
      "我剛才吐了。\n",
      "\n",
      "I lent him a CD.\n",
      "我借给他一盘CD。\n",
      "\n",
      "I like Tom, too.\n",
      "我也喜歡湯姆。\n",
      "\n",
      "I like football.\n",
      "我喜歡足球。\n",
      "\n",
      "I like potatoes.\n",
      "我喜歡土豆。\n",
      "\n",
      "I like the cold.\n",
      "我喜歡寒冷。\n",
      "\n",
      "I like this dog.\n",
      "我喜欢这只狗。\n",
      "\n",
      "I like your car.\n",
      "我喜欢您的车。\n",
      "\n",
      "I lived in Rome.\n",
      "我住在羅馬。\n",
      "\n",
      "I love this car.\n",
      "我愛這台車。\n",
      "\n",
      "I might say yes.\n",
      "我可能会说是。\n",
      "\n",
      "I must help her.\n",
      "我必須幫助她。\n",
      "\n",
      "I need a friend.\n",
      "我需要个朋友。\n",
      "\n",
      "I need evidence.\n",
      "我需要證據。\n",
      "\n",
      "I need you here.\n",
      "我需要你在這裡。\n",
      "\n",
      "I paid the bill.\n",
      "我买了单。\n",
      "\n",
      "I played tennis.\n",
      "我打網球了。\n",
      "\n",
      "I run every day.\n",
      "我每天跑步。\n",
      "\n",
      "I speak Swedish.\n",
      "我说瑞典语。\n",
      "\n",
      "I talked to her.\n",
      "我跟她谈了话。\n",
      "\n",
      "I teach Chinese.\n",
      "我教中文。\n",
      "\n",
      "I think it's OK.\n",
      "我想沒關係。\n",
      "\n",
      "I took a shower.\n",
      "我洗了澡。\n",
      "\n",
      "I want a guitar.\n",
      "我想要一把吉他。\n",
      "\n",
      "I want that bag.\n",
      "我想要那個袋子。\n",
      "\n",
      "I want to drive.\n",
      "我想開車。\n",
      "\n",
      "I was surprised.\n",
      "我吃惊了。\n",
      "\n",
      "I wish you'd go.\n",
      "我希望你去。\n",
      "\n",
      "I woke up early.\n",
      "我起得早。\n",
      "\n",
      "I work too much.\n",
      "我工作得太多了。\n",
      "\n",
      "I'll bring wine.\n",
      "我会带酒来。\n",
      "\n",
      "I'll never stop.\n",
      "我絕不會停。\n",
      "\n",
      "I'm a foreigner.\n",
      "我是一個外國人。\n",
      "\n",
      "I'm a night owl.\n",
      "我是個夜貓子。\n",
      "\n",
      "I'm about ready.\n",
      "我快好了。\n",
      "\n",
      "I'm always here.\n",
      "我一直在這裡。\n",
      "\n",
      "I'm daydreaming.\n",
      "我在做白日梦。\n",
      "\n",
      "I'm feeling fit.\n",
      "我覺得精神很好。\n",
      "\n",
      "I'm left-handed.\n",
      "我是左撇子。\n",
      "\n",
      "I'm not serious.\n",
      "我不是认真的。\n",
      "\n",
      "I'm out of time.\n",
      "我没时间了。\n",
      "\n",
      "I'm really busy.\n",
      "我真的好忙。\n",
      "\n",
      "I'm really cold.\n",
      "我真的冷。\n",
      "\n",
      "I'm still angry.\n",
      "我还饿着呢。\n",
      "\n",
      "I'm very hungry.\n",
      "我很餓。\n",
      "\n",
      "I'm very lonely.\n",
      "我很寂寞。\n",
      "\n",
      "I've had enough.\n",
      "我已經吃飽了。\n",
      "\n",
      "I've had enough.\n",
      "我已經吃飽了。\n",
      "\n",
      "Is Tom Canadian?\n",
      "Tom是加拿大人嗎?\n",
      "\n",
      "Is he breathing?\n",
      "他在呼吸嗎?\n",
      "\n",
      "Is it all there?\n",
      "全都在那裡嗎？\n",
      "\n",
      "Is it too salty?\n",
      "还有多余的盐吗？\n",
      "\n",
      "Is she Japanese?\n",
      "她是日本人嗎？\n",
      "\n",
      "Is this a river?\n",
      "這是一條河嗎?\n",
      "\n",
      "Isn't that mine?\n",
      "那是我的吗？\n",
      "\n",
      "It is up to you.\n",
      "由你來決定。\n",
      "\n",
      "It snowed a lot.\n",
      "下了很多的雪。\n",
      "\n",
      "It was terrible.\n",
      "真糟糕。\n",
      "\n",
      "It was very far.\n",
      "它很遠。\n",
      "\n",
      "It'll be cloudy.\n",
      "天要变多云了。\n",
      "\n",
      "It's a dead end.\n",
      "这是个死胡同。\n",
      "\n",
      "It's a new book.\n",
      "那本書是一本新書。\n",
      "\n",
      "It's a nice day.\n",
      "今天天氣很好。\n",
      "\n",
      "It's a surprise.\n",
      "这是一个惊喜。\n",
      "\n",
      "It's almost six.\n",
      "快要六點了。\n",
      "\n",
      "It's already 11.\n",
      "已经是11点了。\n",
      "\n",
      "It's fine today.\n",
      "今天天气很好。\n",
      "\n",
      "It's impossible.\n",
      "這是不可能的。\n",
      "\n",
      "It's lunch time.\n",
      "午餐時間到了。\n",
      "\n",
      "It's okay to go.\n",
      "你可以走了。\n",
      "\n",
      "It's over there.\n",
      "在那里。\n",
      "\n",
      "It's time to go.\n",
      "該走了。\n",
      "\n",
      "It's time to go.\n",
      "該走了。\n",
      "\n",
      "Jesus loves you.\n",
      "耶穌愛你。\n",
      "\n",
      "Keep on smiling.\n",
      "保持微笑。\n",
      "\n",
      "Keep on working.\n",
      "繼續工作！\n",
      "\n",
      "Keep the change!\n",
      "不用找零钱了。\n",
      "\n",
      "Large, isn't it?\n",
      "很大, 不是嗎?\n",
      "\n",
      "Lemons are sour.\n",
      "檸檬是酸的。\n",
      "\n",
      "Let me go alone.\n",
      "讓我一個人去。\n",
      "\n",
      "Let me see that.\n",
      "讓我看看。\n",
      "\n",
      "Let them decide.\n",
      "讓他們決定。\n",
      "\n",
      "Let's eat sushi.\n",
      "讓我們吃壽司吧。\n",
      "\n",
      "Let's go by bus.\n",
      "讓我們坐公共汽車去。\n",
      "\n",
      "Let's not argue.\n",
      "我們別吵了。\n",
      "\n",
      "Let's turn back.\n",
      "我们掉头吧！\n",
      "\n",
      "Look at the sky.\n",
      "看天上。\n",
      "\n",
      "Look behind you.\n",
      "瞧你身後。\n",
      "\n",
      "Make it smaller.\n",
      "把它弄小一點。\n",
      "\n",
      "May I leave now?\n",
      "我现在能走了吗？\n",
      "\n",
      "May I try it on?\n",
      "我能试一下吗？\n",
      "\n",
      "Maybe next time.\n",
      "也许下一次吧。\n",
      "\n",
      "Men should work.\n",
      "男人应该工作。\n",
      "\n",
      "Merry Christmas!\n",
      "聖誕快樂。\n",
      "\n",
      "Mom, I'm hungry.\n",
      "妈妈，我肚子饿了。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1100):\n",
    "    test = encoder_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    #print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have brothers.\n",
      "我有兄弟。\n",
      "\n",
      "I have ten pens.\n",
      "我有十支筆。\n",
      "\n",
      "I have to hurry!\n",
      "我要赶紧了!\n",
      "\n",
      "I have two cats.\n",
      "我有两只猫。\n",
      "\n",
      "I have two sons.\n",
      "我有兩個兒子。\n",
      "\n",
      "I just threw up.\n",
      "我剛才吐了。\n",
      "\n",
      "I lent him a CD.\n",
      "我借给他一盘CD。\n",
      "\n",
      "I like Tom, too.\n",
      "我也喜歡湯姆。\n",
      "\n",
      "I like football.\n",
      "我喜歡足球。\n",
      "\n",
      "I like potatoes.\n",
      "我喜歡土豆。\n",
      "\n",
      "I like the cold.\n",
      "我喜歡寒冷。\n",
      "\n",
      "I like this dog.\n",
      "我喜欢这只狗。\n",
      "\n",
      "I like your car.\n",
      "我喜欢您的车。\n",
      "\n",
      "I lived in Rome.\n",
      "我住在羅馬。\n",
      "\n",
      "I love this car.\n",
      "我愛這台車。\n",
      "\n",
      "I might say yes.\n",
      "我可能会说是。\n",
      "\n",
      "I must help her.\n",
      "我必須幫助她。\n",
      "\n",
      "I need a friend.\n",
      "我需要个朋友。\n",
      "\n",
      "I need evidence.\n",
      "我需要證據。\n",
      "\n",
      "I need you here.\n",
      "我需要你在這裡。\n",
      "\n",
      "I paid the bill.\n",
      "我买了单。\n",
      "\n",
      "I played tennis.\n",
      "我打網球了。\n",
      "\n",
      "I run every day.\n",
      "我每天跑步。\n",
      "\n",
      "I speak Swedish.\n",
      "我说瑞典语。\n",
      "\n",
      "I talked to her.\n",
      "我跟她谈了话。\n",
      "\n",
      "I teach Chinese.\n",
      "我教中文。\n",
      "\n",
      "I think it's OK.\n",
      "我想沒關係。\n",
      "\n",
      "I took a shower.\n",
      "我洗了澡。\n",
      "\n",
      "I want a guitar.\n",
      "我想要一把吉他。\n",
      "\n",
      "I want that bag.\n",
      "我想要那個袋子。\n",
      "\n",
      "I want to drive.\n",
      "我想開車。\n",
      "\n",
      "I was surprised.\n",
      "我吃惊了。\n",
      "\n",
      "I wish you'd go.\n",
      "我希望你去。\n",
      "\n",
      "I woke up early.\n",
      "我起得早。\n",
      "\n",
      "I work too much.\n",
      "我工作得太多了。\n",
      "\n",
      "I'll bring wine.\n",
      "我会带酒来。\n",
      "\n",
      "I'll never stop.\n",
      "我絕不會停。\n",
      "\n",
      "I'm a foreigner.\n",
      "我是一個外國人。\n",
      "\n",
      "I'm a night owl.\n",
      "我是個夜貓子。\n",
      "\n",
      "I'm about ready.\n",
      "我快好了。\n",
      "\n",
      "I'm always here.\n",
      "我一直在這裡。\n",
      "\n",
      "I'm daydreaming.\n",
      "我在做白日梦。\n",
      "\n",
      "I'm feeling fit.\n",
      "我覺得精神很好。\n",
      "\n",
      "I'm left-handed.\n",
      "我是左撇子。\n",
      "\n",
      "I'm not serious.\n",
      "我不是认真的。\n",
      "\n",
      "I'm out of time.\n",
      "我没时间了。\n",
      "\n",
      "I'm really busy.\n",
      "我真的好忙。\n",
      "\n",
      "I'm really cold.\n",
      "我真的冷。\n",
      "\n",
      "I'm still angry.\n",
      "我还饿着呢。\n",
      "\n",
      "I'm very hungry.\n",
      "我很餓。\n",
      "\n",
      "I'm very lonely.\n",
      "我很寂寞。\n",
      "\n",
      "I've had enough.\n",
      "我已經受夠了。\n",
      "\n",
      "I've had enough.\n",
      "我已經受夠了。\n",
      "\n",
      "Is Tom Canadian?\n",
      "Tom是我高。\n",
      "\n",
      "Is he breathing?\n",
      "他在呼吸嗎?\n",
      "\n",
      "Is it all there?\n",
      "全都在那裡嗎？\n",
      "\n",
      "Is it too salty?\n",
      "还有多余的盐吗？\n",
      "\n",
      "Is she Japanese?\n",
      "她是日本人嗎？\n",
      "\n",
      "Is this a river?\n",
      "這是一條河嗎?\n",
      "\n",
      "Isn't that mine?\n",
      "那是我的吗？\n",
      "\n",
      "It is up to you.\n",
      "由你來決定。\n",
      "\n",
      "It snowed a lot.\n",
      "下了很多的雪。\n",
      "\n",
      "It was terrible.\n",
      "真糟糕。\n",
      "\n",
      "It was very far.\n",
      "它很遠。\n",
      "\n",
      "It'll be cloudy.\n",
      "天要变多云了。\n",
      "\n",
      "It's a dead end.\n",
      "这是个死胡同。\n",
      "\n",
      "It's a new book.\n",
      "那本書是一本新書。\n",
      "\n",
      "It's a nice day.\n",
      "今天天氣很好。\n",
      "\n",
      "It's a surprise.\n",
      "这是一个惊喜。\n",
      "\n",
      "It's almost six.\n",
      "快要六點了。\n",
      "\n",
      "It's already 11.\n",
      "已经是11点了。\n",
      "\n",
      "It's fine today.\n",
      "今天天气很好。\n",
      "\n",
      "It's impossible.\n",
      "這是不可能的。\n",
      "\n",
      "It's lunch time.\n",
      "午餐時間到了。\n",
      "\n",
      "It's okay to go.\n",
      "你可以走了。\n",
      "\n",
      "It's over there.\n",
      "在那里。\n",
      "\n",
      "It's time to go.\n",
      "是該離開的時候了。\n",
      "\n",
      "It's time to go.\n",
      "是該離開的時候了。\n",
      "\n",
      "Jesus loves you.\n",
      "耶穌愛你。\n",
      "\n",
      "Keep on smiling.\n",
      "保持微笑。\n",
      "\n",
      "Keep on working.\n",
      "繼續工作！\n",
      "\n",
      "Keep the change!\n",
      "不用找零钱了。\n",
      "\n",
      "Large, isn't it?\n",
      "很大, 不是嗎?\n",
      "\n",
      "Lemons are sour.\n",
      "檸檬是酸的。\n",
      "\n",
      "Let me go alone.\n",
      "讓我一個人去。\n",
      "\n",
      "Let me see that.\n",
      "讓我看看。\n",
      "\n",
      "Let them decide.\n",
      "讓他們決定。\n",
      "\n",
      "Let's eat sushi.\n",
      "讓我們吃壽司吧。\n",
      "\n",
      "Let's go by bus.\n",
      "讓我們坐公共汽車去。\n",
      "\n",
      "Let's not argue.\n",
      "我們別吵了。\n",
      "\n",
      "Let's turn back.\n",
      "我们掉头吧！\n",
      "\n",
      "Look at the sky.\n",
      "看天上。\n",
      "\n",
      "Look behind you.\n",
      "瞧你身後。\n",
      "\n",
      "Make it smaller.\n",
      "把它弄小一點。\n",
      "\n",
      "May I leave now?\n",
      "我现在能走了吗？\n",
      "\n",
      "May I try it on?\n",
      "我能试一下吗？\n",
      "\n",
      "Maybe next time.\n",
      "也许下一次吧。\n",
      "\n",
      "Men should work.\n",
      "男人应该工作。\n",
      "\n",
      "Merry Christmas!\n",
      "聖誕快樂。\n",
      "\n",
      "Mom, I'm hungry.\n",
      "妈妈，我肚子饿了。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1100):\n",
    "    test = encoder_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    #print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T01:14:56.826189Z",
     "start_time": "2020-11-29T01:14:14.163888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have brothers.\n",
      "我有兄弟。\n",
      "\n",
      "I have ten pens.\n",
      "我有十支筆。\n",
      "\n",
      "I have to hurry!\n",
      "我要赶紧了!\n",
      "\n",
      "I have two cats.\n",
      "我有两只猫。\n",
      "\n",
      "I have two sons.\n",
      "我有兩個兒子。\n",
      "\n",
      "I just threw up.\n",
      "我剛才吐了。\n",
      "\n",
      "I lent him a CD.\n",
      "我借给他一盘CD。\n",
      "\n",
      "I like Tom, too.\n",
      "我也喜歡湯姆。\n",
      "\n",
      "I like football.\n",
      "我喜歡足球。\n",
      "\n",
      "I like potatoes.\n",
      "我喜歡土豆。\n",
      "\n",
      "I like the cold.\n",
      "我喜歡寒冷。\n",
      "\n",
      "I like this dog.\n",
      "我喜欢这只狗。\n",
      "\n",
      "I like your car.\n",
      "我喜欢您的车。\n",
      "\n",
      "I lived in Rome.\n",
      "我住在羅馬。\n",
      "\n",
      "I love this car.\n",
      "我愛這台車。\n",
      "\n",
      "I might say yes.\n",
      "我可能会说是。\n",
      "\n",
      "I must help her.\n",
      "我必須幫助她。\n",
      "\n",
      "I need a friend.\n",
      "我需要个朋友。\n",
      "\n",
      "I need evidence.\n",
      "我需要證據。\n",
      "\n",
      "I need you here.\n",
      "我需要你在這裡。\n",
      "\n",
      "I paid the bill.\n",
      "我买了单。\n",
      "\n",
      "I played tennis.\n",
      "我打網球了。\n",
      "\n",
      "I run every day.\n",
      "我每天跑步。\n",
      "\n",
      "I speak Swedish.\n",
      "我说瑞典语。\n",
      "\n",
      "I talked to her.\n",
      "我跟她谈了话。\n",
      "\n",
      "I teach Chinese.\n",
      "我教中文。\n",
      "\n",
      "I think it's OK.\n",
      "我想沒關係。\n",
      "\n",
      "I took a shower.\n",
      "我洗了澡。\n",
      "\n",
      "I want a guitar.\n",
      "我想要一把吉他。\n",
      "\n",
      "I want that bag.\n",
      "我想要那個袋子。\n",
      "\n",
      "I want to drive.\n",
      "我想開車。\n",
      "\n",
      "I was surprised.\n",
      "我吃惊了。\n",
      "\n",
      "I wish you'd go.\n",
      "我希望你去。\n",
      "\n",
      "I woke up early.\n",
      "我起得早。\n",
      "\n",
      "I work too much.\n",
      "我工作得太多了。\n",
      "\n",
      "I'll bring wine.\n",
      "我会带酒来。\n",
      "\n",
      "I'll never stop.\n",
      "我絕不會停。\n",
      "\n",
      "I'm a foreigner.\n",
      "我是一個外國人。\n",
      "\n",
      "I'm a night owl.\n",
      "我是個夜貓子。\n",
      "\n",
      "I'm about ready.\n",
      "我快好了。\n",
      "\n",
      "I'm always here.\n",
      "我一直在這裡。\n",
      "\n",
      "I'm daydreaming.\n",
      "我在做白日梦。\n",
      "\n",
      "I'm feeling fit.\n",
      "我覺得精神很好。\n",
      "\n",
      "I'm left-handed.\n",
      "我是左撇子。\n",
      "\n",
      "I'm not serious.\n",
      "我不是认真的。\n",
      "\n",
      "I'm out of time.\n",
      "我没时间了。\n",
      "\n",
      "I'm really busy.\n",
      "我真的好忙。\n",
      "\n",
      "I'm really cold.\n",
      "我真的冷。\n",
      "\n",
      "I'm still angry.\n",
      "我还饿着呢。\n",
      "\n",
      "I'm very hungry.\n",
      "我很餓。\n",
      "\n",
      "I'm very lonely.\n",
      "我很寂寞。\n",
      "\n",
      "I've had enough.\n",
      "我已經受夠了。\n",
      "\n",
      "I've had enough.\n",
      "我已經受夠了。\n",
      "\n",
      "Is Tom Canadian?\n",
      "Tom是加拿大人嗎?\n",
      "\n",
      "Is he breathing?\n",
      "他在呼吸嗎?\n",
      "\n",
      "Is it all there?\n",
      "全都在那裡嗎？\n",
      "\n",
      "Is it too salty?\n",
      "还有多余的盐吗？\n",
      "\n",
      "Is she Japanese?\n",
      "她是日本人嗎？\n",
      "\n",
      "Is this a river?\n",
      "這是一條河嗎?\n",
      "\n",
      "Isn't that mine?\n",
      "那是我的吗？\n",
      "\n",
      "It is up to you.\n",
      "由你來決定。\n",
      "\n",
      "It snowed a lot.\n",
      "下了很多的雪。\n",
      "\n",
      "It was terrible.\n",
      "真糟糕。\n",
      "\n",
      "It was very far.\n",
      "它很遠。\n",
      "\n",
      "It'll be cloudy.\n",
      "天要变多云了。\n",
      "\n",
      "It's a dead end.\n",
      "这是个死胡同。\n",
      "\n",
      "It's a new book.\n",
      "那本書是一本新書。\n",
      "\n",
      "It's a nice day.\n",
      "今天天氣很好。\n",
      "\n",
      "It's a surprise.\n",
      "这是一个惊喜。\n",
      "\n",
      "It's almost six.\n",
      "快要六點了。\n",
      "\n",
      "It's already 11.\n",
      "已经是11点了。\n",
      "\n",
      "It's fine today.\n",
      "今天天气很好。\n",
      "\n",
      "It's impossible.\n",
      "這是不可能的。\n",
      "\n",
      "It's lunch time.\n",
      "午餐時間到了。\n",
      "\n",
      "It's okay to go.\n",
      "你可以走了。\n",
      "\n",
      "It's over there.\n",
      "在那里。\n",
      "\n",
      "It's time to go.\n",
      "該走了。\n",
      "\n",
      "It's time to go.\n",
      "該走了。\n",
      "\n",
      "Jesus loves you.\n",
      "耶穌愛你。\n",
      "\n",
      "Keep on smiling.\n",
      "保持微笑。\n",
      "\n",
      "Keep on working.\n",
      "繼續工作！\n",
      "\n",
      "Keep the change!\n",
      "不用找零钱了。\n",
      "\n",
      "Large, isn't it?\n",
      "很大, 不是嗎?\n",
      "\n",
      "Lemons are sour.\n",
      "檸檬是酸的。\n",
      "\n",
      "Let me go alone.\n",
      "讓我一個人去。\n",
      "\n",
      "Let me see that.\n",
      "讓我看看。\n",
      "\n",
      "Let them decide.\n",
      "讓他們決定。\n",
      "\n",
      "Let's eat sushi.\n",
      "讓我們吃壽司吧。\n",
      "\n",
      "Let's go by bus.\n",
      "讓我們坐公共汽車去。\n",
      "\n",
      "Let's not argue.\n",
      "我們別吵了。\n",
      "\n",
      "Let's turn back.\n",
      "我们掉头吧！\n",
      "\n",
      "Look at the sky.\n",
      "看天上。\n",
      "\n",
      "Look behind you.\n",
      "瞧你身後。\n",
      "\n",
      "Make it smaller.\n",
      "把它弄小一點。\n",
      "\n",
      "May I leave now?\n",
      "我现在能走了吗？\n",
      "\n",
      "May I try it on?\n",
      "我能试一下吗？\n",
      "\n",
      "Maybe next time.\n",
      "也许下一次吧。\n",
      "\n",
      "Men should work.\n",
      "男人应该工作。\n",
      "\n",
      "Merry Christmas!\n",
      "聖誕快樂。\n",
      "\n",
      "Mom, I'm hungry.\n",
      "妈妈，我肚子饿了。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1100):\n",
    "    test = encoder_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    #print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T12:35:30.742218Z",
     "start_time": "2020-11-28T12:34:38.396080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've just finished breakfast.\n",
      "我們喜歡看電視。\n",
      "\n",
      "Weather's pretty nice tonight.\n",
      "湯姆明天去学校。\n",
      "\n",
      "Weeds sprang up in the garden.\n",
      "我們與他們交朋友了。\n",
      "\n",
      "What are we having for dinner?\n",
      "公園裡在這裡做？\n",
      "\n",
      "What are you doing down there?\n",
      "你今晚在做什麼？\n",
      "\n",
      "What are you guys going to do?\n",
      "你说的汤姆什么？\n",
      "\n",
      "What do you eat for breakfast?\n",
      "這隻鳥叫什麼?\n",
      "\n",
      "What do you think I was doing?\n",
      "你認為我想要甚麼？\n",
      "\n",
      "What don't you want us to see?\n",
      "你们不能做不如何？\n",
      "\n",
      "What if something gets broken?\n",
      "那是真的呢？\n",
      "\n",
      "What is done cannot be undone.\n",
      "他的想走地裡了？\n",
      "\n",
      "What is the name of that bird?\n",
      "这是什么意思？\n",
      "\n",
      "What kind of meal did you eat?\n",
      "我要回家汤姆？\n",
      "\n",
      "What kind of wine do you have?\n",
      "我要去做什麼？\n",
      "\n",
      "What kind of work will you do?\n",
      "我要的汤姆是甚么？\n",
      "\n",
      "What made him change his mind?\n",
      "她是最好的錯呢？\n",
      "\n",
      "What subject do you like best?\n",
      "你喜歡什麼運動？\n",
      "\n",
      "What time does boarding begin?\n",
      "她是怎样的人呢？\n",
      "\n",
      "What time does the play begin?\n",
      "我们需要做什么？\n",
      "\n",
      "What time is it by your watch?\n",
      "你的床怎麼樣？\n",
      "\n",
      "What time is it in London now?\n",
      "他说了我的？\n",
      "\n",
      "What time shall I pick you up?\n",
      "可以把它給我我看看起来的玛包的。\n",
      "\n",
      "What's the climate there like?\n",
      "Wifi的是Tom没有喜歡？\n",
      "\n",
      "What's the weather like there?\n",
      "天氣怎麼樣？\n",
      "\n",
      "What's the weather like today?\n",
      "多點的什麼不這麼？\n",
      "\n",
      "What's the width of this road?\n",
      "什么时候开始？\n",
      "\n",
      "What's your favorite beverage?\n",
      "那個是我的房子？\n",
      "\n",
      "What's your favorite iPad app?\n",
      "那会让你有什么问题？\n",
      "\n",
      "What's your home phone number?\n",
      "你喜歡什麼那東西？\n",
      "\n",
      "When did he say he would come?\n",
      "你想要什麼幫我的？\n",
      "\n",
      "When did she break the window?\n",
      "麻煩您了我們的時方？\n",
      "\n",
      "When do you have to go to bed?\n",
      "你不該去哪裡?\n",
      "\n",
      "When is it convenient for you?\n",
      "今天幾點？\n",
      "\n",
      "Where did you go for vacation?\n",
      "你在哪儿什麼？\n",
      "\n",
      "Where do you want to go today?\n",
      "你想要的話來汁。\n",
      "\n",
      "Where do you watch television?\n",
      "你在哪裡？\n",
      "\n",
      "Where is the Japanese Embassy?\n",
      "這家為如何?\n",
      "\n",
      "Where should I put my laundry?\n",
      "您的東西在哪裡？\n",
      "\n",
      "Where will the bus pick us up?\n",
      "让我们要做任何么样。\n",
      "\n",
      "Where's the nearest drugstore?\n",
      "她在哪儿？\n",
      "\n",
      "Who do you suggest we talk to?\n",
      "誰告訴了你這個消息？\n",
      "\n",
      "Who is going to speak tonight?\n",
      "那時嬰兒是個？\n",
      "\n",
      "Who was the letter written to?\n",
      "今天是想出什的？\n",
      "\n",
      "Why aren't you coming with us?\n",
      "你给我为什么可日？\n",
      "\n",
      "Why did she go to the station?\n",
      "为什么他会做这事的事呢？\n",
      "\n",
      "Why did you come home so late?\n",
      "你为什么来了日本的？\n",
      "\n",
      "Why didn't you dance with him?\n",
      "你認為如何?\n",
      "\n",
      "Why don't you have some sushi?\n",
      "你為甚麼不舉行派對？\n",
      "\n",
      "Why should I apologize to you?\n",
      "为什么我叫請我？\n",
      "\n",
      "Will you all be here tomorrow?\n",
      "聽天不好看那了吗？\n",
      "\n",
      "Will you go on foot or by bus?\n",
      "請你把鹽遞給我好嗎？\n",
      "\n",
      "Will you lend me your bicycle?\n",
      "您你不用这个里吗？\n",
      "\n",
      "Will you stay at home tonight?\n",
      "請你把鹽遞給我好嗎？\n",
      "\n",
      "Will you switch seats with me?\n",
      "汤姆不在做白的。\n",
      "\n",
      "Wine made here is very famous.\n",
      "汤姆是我们最大的儿子。\n",
      "\n",
      "World War I broke out in 1914.\n",
      "我们的位子在一儿包？\n",
      "\n",
      "Would you lend me your pencil?\n",
      "能借我支铅笔吗？\n",
      "\n",
      "Would you like me to help you?\n",
      "請您把窗戶關起來好嗎?\n",
      "\n",
      "Would you like some more beef?\n",
      "你要來點些錢?\n",
      "\n",
      "Would you like some more beer?\n",
      "你要來點些錢？\n",
      "\n",
      "Would you like some more cake?\n",
      "你要來點這麼?\n",
      "\n",
      "Would you like to eat with us?\n",
      "請你把鹽遞給我好嗎?\n",
      "\n",
      "Would you mind coming with me?\n",
      "想要幫點我們的高？\n",
      "\n",
      "Yes, it's such a nice evening.\n",
      "他們着不怕。\n",
      "\n",
      "You and he are both very kind.\n",
      "你和我同龄。\n",
      "\n",
      "You can borrow my car anytime.\n",
      "你怎麼找到這個對這個問好。\n",
      "\n",
      "You can eat whatever you like.\n",
      "你讓我快樂。\n",
      "\n",
      "You can stay here if you like.\n",
      "你讓我快樂。\n",
      "\n",
      "You can watch TV after supper.\n",
      "你和湯姆一定高等。\n",
      "\n",
      "You can't count on their help.\n",
      "你不再能不到。\n",
      "\n",
      "You could be right, I suppose.\n",
      "你和我一樣做。\n",
      "\n",
      "You don't believe Tom, do you?\n",
      "你們不會說。\n",
      "\n",
      "You don't need to study today.\n",
      "你不能幫湯姆可以。\n",
      "\n",
      "You dropped your handkerchief.\n",
      "你们來得玩笑了多的。\n",
      "\n",
      "You have to leave home at six.\n",
      "你有一双书。\n",
      "\n",
      "You look like you're confused.\n",
      "如果你想，你可以去。\n",
      "\n",
      "You may sit wherever you like.\n",
      "你必須跟我說的。\n",
      "\n",
      "You must make up for the loss.\n",
      "你看起來比湯好。\n",
      "\n",
      "You must pay attention to him.\n",
      "你不能让我们可能去玩得。\n",
      "\n",
      "You need to go home right now.\n",
      "你和朋友是一起好的？\n",
      "\n",
      "You remind me of your brother.\n",
      "你太年輕，不能退休。\n",
      "\n",
      "You should be more reasonable.\n",
      "你應該去請醫生。\n",
      "\n",
      "You should get your car fixed.\n",
      "你喜歡大對的已好男人。\n",
      "\n",
      "You should have visited Kyoto.\n",
      "你有点好多好。\n",
      "\n",
      "You should have worked harder.\n",
      "你看來這是你的一個。\n",
      "\n",
      "You should stay at home today.\n",
      "你了解他比他的年齡。\n",
      "\n",
      "You should stay away from Tom.\n",
      "如果你下一话，這是汤姆的。\n",
      "\n",
      "You should tell him the truth.\n",
      "你该把事实说。\n",
      "\n",
      "You should tell him the truth.\n",
      "你该把事实说。\n",
      "\n",
      "You shouldn't have come alone.\n",
      "你不應該做的。\n",
      "\n",
      "You shouldn't have gone there.\n",
      "你不應該做的。\n",
      "\n",
      "You used to smoke, didn't you?\n",
      "你明天喝得不能嗎？\n",
      "\n",
      "You'd better go back home now.\n",
      "你最好尽快去睡著。\n",
      "\n",
      "You'd better not go out today.\n",
      "你今天最好不要去。\n",
      "\n",
      "You're a better skier than me.\n",
      "你是來的使我。\n",
      "\n",
      "You're drinking out of my cup.\n",
      "你太太在生能，你打开？\n",
      "\n",
      "You're not satisfied, are you?\n",
      "你不该在这里工作。\n",
      "\n",
      "You're sick. You have to rest.\n",
      "你來不會我的一學。\n",
      "\n",
      "You're very brave, aren't you?\n",
      "你來得很快。\n",
      "\n",
      "You've got a lot of willpower.\n",
      "你太年輕，不能退休。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(9900,10000):\n",
    "    test = encoder_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    #print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T01:15:55.155646Z",
     "start_time": "2020-11-29T01:15:03.354727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've just finished breakfast.\n",
      "我們很快就像他的了。\n",
      "\n",
      "Weather's pretty nice tonight.\n",
      "湯姆明天都能好。\n",
      "\n",
      "Weeds sprang up in the garden.\n",
      "我們的名字在这里工作。\n",
      "\n",
      "What are we having for dinner?\n",
      "在這儿子可以什麼？\n",
      "\n",
      "What are you doing down there?\n",
      "你今天在做什麼？\n",
      "\n",
      "What are you guys going to do?\n",
      "你在看什麼？\n",
      "\n",
      "What do you eat for breakfast?\n",
      "這個花叫什麼名字？\n",
      "\n",
      "What do you think I was doing?\n",
      "你認為如何?\n",
      "\n",
      "What don't you want us to see?\n",
      "你為什麼跟我說了謊？\n",
      "\n",
      "What if something gets broken?\n",
      "這隻鳥叫鞋子?\n",
      "\n",
      "What is done cannot be undone.\n",
      "他說的話不是爱。\n",
      "\n",
      "What is the name of that bird?\n",
      "他是怎么样的人呢？\n",
      "\n",
      "What kind of meal did you eat?\n",
      "我们的號是真的？\n",
      "\n",
      "What kind of wine do you have?\n",
      "我想知道什麼？\n",
      "\n",
      "What kind of work will you do?\n",
      "我想要你的什麼?\n",
      "\n",
      "What made him change his mind?\n",
      "她为什么生气？\n",
      "\n",
      "What subject do you like best?\n",
      "你在店裡買了什麼？\n",
      "\n",
      "What time does boarding begin?\n",
      "她說的話讓我思？\n",
      "\n",
      "What time does the play begin?\n",
      "她想要什麼?\n",
      "\n",
      "What time is it by your watch?\n",
      "你的狗怎麼了？\n",
      "\n",
      "What time is it in London now?\n",
      "他想要什么事？\n",
      "\n",
      "What time shall I pick you up?\n",
      "可能把你的袋子還在問題嗎？\n",
      "\n",
      "What's the climate there like?\n",
      "到利物浦的票價多錢？\n",
      "\n",
      "What's the weather like there?\n",
      "到利物浦的票價多錢？\n",
      "\n",
      "What's the weather like today?\n",
      "到這隻鳥叫警察。\n",
      "\n",
      "What's the width of this road?\n",
      "這首曲子叫什麼名？\n",
      "\n",
      "What's your favorite beverage?\n",
      "你最喜歡什麼氣？\n",
      "\n",
      "What's your favorite iPad app?\n",
      "你的生日是几号？\n",
      "\n",
      "What's your home phone number?\n",
      "你的生氣有什么？\n",
      "\n",
      "When did he say he would come?\n",
      "你什么时候结婚的？\n",
      "\n",
      "When did she break the window?\n",
      "車是什么时候出生的？\n",
      "\n",
      "When do you have to go to bed?\n",
      "你想跟誰說話？\n",
      "\n",
      "When is it convenient for you?\n",
      "找到你們不甚麼？\n",
      "\n",
      "Where did you go for vacation?\n",
      "你在哪裡買這裡工作？\n",
      "\n",
      "Where do you want to go today?\n",
      "你在哪裡買了雙的鞋子？\n",
      "\n",
      "Where do you watch television?\n",
      "你在哪裡?\n",
      "\n",
      "Where is the Japanese Embassy?\n",
      "最近的藥房在哪裡？\n",
      "\n",
      "Where should I put my laundry?\n",
      "您的报告怎么样？\n",
      "\n",
      "Where will the bus pick us up?\n",
      "把我的藥在可以幫助我？\n",
      "\n",
      "Where's the nearest drugstore?\n",
      "最近車站在哪裡？\n",
      "\n",
      "Who do you suggest we talk to?\n",
      "誰告訴你這個故事？\n",
      "\n",
      "Who is going to speak tonight?\n",
      "谁教你们法语？\n",
      "\n",
      "Who was the letter written to?\n",
      "谁法是真的。\n",
      "\n",
      "Why aren't you coming with us?\n",
      "为什么你不对我们们大来的？\n",
      "\n",
      "Why did she go to the station?\n",
      "为什么他会做这样的事呢？\n",
      "\n",
      "Why did you come home so late?\n",
      "你為什麼去玩具需要你？\n",
      "\n",
      "Why didn't you dance with him?\n",
      "为什么你不怕看我就是同？\n",
      "\n",
      "Why don't you have some sushi?\n",
      "为什么你不吃蔬菜？\n",
      "\n",
      "Why should I apologize to you?\n",
      "为什么汤姆叫我玛丽？\n",
      "\n",
      "Will you all be here tomorrow?\n",
      "明天你下去哪儿嗎？\n",
      "\n",
      "Will you go on foot or by bus?\n",
      "你愿意等吗 ?\n",
      "\n",
      "Will you lend me your bicycle?\n",
      "您天会下你的名字嗎？\n",
      "\n",
      "Will you stay at home tonight?\n",
      "你要來點請東西嗎?\n",
      "\n",
      "Will you switch seats with me?\n",
      "汤姆，在做得这样的事情。\n",
      "\n",
      "Wine made here is very famous.\n",
      "老师您有会议的人?\n",
      "\n",
      "World War I broke out in 1914.\n",
      "幫姆人是被他的？\n",
      "\n",
      "Would you lend me your pencil?\n",
      "你可以借我你的刀嗎?\n",
      "\n",
      "Would you like me to help you?\n",
      "你想一點兒子上學校嗎？\n",
      "\n",
      "Would you like some more beef?\n",
      "你要喝點茶嗎？\n",
      "\n",
      "Would you like some more beer?\n",
      "你要用點來嗎？\n",
      "\n",
      "Would you like some more cake?\n",
      "你要喝點什麼嗎？\n",
      "\n",
      "Would you like to eat with us?\n",
      "請您把窗戶關起來好嗎？\n",
      "\n",
      "Would you mind coming with me?\n",
      "誰您想去游泳？\n",
      "\n",
      "Yes, it's such a nice evening.\n",
      "他的衣服總是來很臭。\n",
      "\n",
      "You and he are both very kind.\n",
      "你和我有一張朋友。\n",
      "\n",
      "You can borrow my car anytime.\n",
      "你的來會對你。\n",
      "\n",
      "You can eat whatever you like.\n",
      "你不能待一床。\n",
      "\n",
      "You can stay here if you like.\n",
      "你可以選擇你喜歡的。\n",
      "\n",
      "You can watch TV after supper.\n",
      "你和我一起朋友。\n",
      "\n",
      "You can't count on their help.\n",
      "你不能去外面去。\n",
      "\n",
      "You could be right, I suppose.\n",
      "你應該把大門。\n",
      "\n",
      "You don't believe Tom, do you?\n",
      "你不太多著不嗎？\n",
      "\n",
      "You don't need to study today.\n",
      "汤姆不必要做我的钱包。\n",
      "\n",
      "You dropped your handkerchief.\n",
      "你知道他們是加拿大的人。\n",
      "\n",
      "You have to leave home at six.\n",
      "你必须遵守规则。\n",
      "\n",
      "You look like you're confused.\n",
      "你看起來像湯姆。\n",
      "\n",
      "You may sit wherever you like.\n",
      "你只是一个生活的。\n",
      "\n",
      "You must make up for the loss.\n",
      "你只要說這對我的英語。\n",
      "\n",
      "You must pay attention to him.\n",
      "你不應該一切。\n",
      "\n",
      "You need to go home right now.\n",
      "你和我的不喜说它。\n",
      "\n",
      "You remind me of your brother.\n",
      "你明天會來請語。\n",
      "\n",
      "You should be more reasonable.\n",
      "你應該把努力的架上。\n",
      "\n",
      "You should get your car fixed.\n",
      "你该理发了。\n",
      "\n",
      "You should have visited Kyoto.\n",
      "你本應該這樣做的。\n",
      "\n",
      "You should have worked harder.\n",
      "你本應該更明白的。\n",
      "\n",
      "You should stay at home today.\n",
      "你该去哪里游泳。\n",
      "\n",
      "You should stay away from Tom.\n",
      "你的比你高得湯姆。\n",
      "\n",
      "You should tell him the truth.\n",
      "你该把事实说出来。\n",
      "\n",
      "You should tell him the truth.\n",
      "你该把事实说出来。\n",
      "\n",
      "You shouldn't have come alone.\n",
      "我不應該做的。\n",
      "\n",
      "You shouldn't have gone there.\n",
      "你不應該做那件事的。\n",
      "\n",
      "You used to smoke, didn't you?\n",
      "你對你見湯姆，不是嗎？\n",
      "\n",
      "You'd better go back home now.\n",
      "你最好尽快就做。\n",
      "\n",
      "You'd better not go out today.\n",
      "你今天可以做到。\n",
      "\n",
      "You're a better skier than me.\n",
      "你是个请跟人。\n",
      "\n",
      "You're drinking out of my cup.\n",
      "你太太在生你的氣。\n",
      "\n",
      "You're not satisfied, are you?\n",
      "你不该吃，这么吗？\n",
      "\n",
      "You're sick. You have to rest.\n",
      "你们都很輕。\n",
      "\n",
      "You're very brave, aren't you?\n",
      "你真是遲到了。\n",
      "\n",
      "You've got a lot of willpower.\n",
      "你必須派人去請醫生來。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(9900,10000):\n",
    "    test = encoder_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    #print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:13:01.837400Z",
     "start_time": "2020-11-30T03:12:07.184604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've just finished breakfast.\n",
      "我們是個老師。\n",
      "\n",
      "Weather's pretty nice tonight.\n",
      "媽媽了一下樹點的胃個。\n",
      "\n",
      "Weeds sprang up in the garden.\n",
      "我們可以在彈鋼琴。\n",
      "\n",
      "What are we having for dinner?\n",
      "怎么天氣？\n",
      "\n",
      "What are you doing down there?\n",
      "你为什么没什么？\n",
      "\n",
      "What are you guys going to do?\n",
      "你在它什麼?\n",
      "\n",
      "What do you eat for breakfast?\n",
      "這個是你的姑姑給我做的？\n",
      "\n",
      "What do you think I was doing?\n",
      "你说什么石头？\n",
      "\n",
      "What don't you want us to see?\n",
      "你為什麼讓我看起来？\n",
      "\n",
      "What if something gets broken?\n",
      "到利的票发生是什麼？\n",
      "\n",
      "What is done cannot be undone.\n",
      "他說的不石道的是什麼。\n",
      "\n",
      "What is the name of that bird?\n",
      "这是什么石头？\n",
      "\n",
      "What kind of meal did you eat?\n",
      "我们应该做什么样的作汤姆？\n",
      "\n",
      "What kind of wine do you have?\n",
      "汤姆知道我的什么？\n",
      "\n",
      "What kind of work will you do?\n",
      "我說的是真的吗？\n",
      "\n",
      "What made him change his mind?\n",
      "她是从哪买的书？\n",
      "\n",
      "What subject do you like best?\n",
      "你的狗怎麼了？\n",
      "\n",
      "What time does boarding begin?\n",
      "她是怎样的人呢？\n",
      "\n",
      "What time does the play begin?\n",
      "她把自然的红色了還\n",
      "\n",
      "What time is it by your watch?\n",
      "你的狗怎麼了？\n",
      "\n",
      "What time is it in London now?\n",
      "他的现在不用了？\n",
      "\n",
      "What time shall I pick you up?\n",
      "你說的話当是什麼樣？\n",
      "\n",
      "What's the climate there like?\n",
      "到利物浦的票價多少錢？\n",
      "\n",
      "What's the weather like there?\n",
      "到火怎麼樣才能？\n",
      "\n",
      "What's the weather like today?\n",
      "我们的回答是的主意。\n",
      "\n",
      "What's the width of this road?\n",
      "她是怎么样的人？\n",
      "\n",
      "What's your favorite beverage?\n",
      "你最喜歡什麼氣？\n",
      "\n",
      "What's your favorite iPad app?\n",
      "你最喜歡什麼氣？\n",
      "\n",
      "What's your home phone number?\n",
      "你正在听到這個東西嗎？\n",
      "\n",
      "When did he say he would come?\n",
      "你什么时候睡觉？\n",
      "\n",
      "When did she break the window?\n",
      "車是什么时候出生的？\n",
      "\n",
      "When do you have to go to bed?\n",
      "你跟誰是什麼？\n",
      "\n",
      "When is it convenient for you?\n",
      "汤姆是个友好的媽媽。\n",
      "\n",
      "Where did you go for vacation?\n",
      "你在哪裡買這雙鞋子?\n",
      "\n",
      "Where do you want to go today?\n",
      "你要去哪裡?\n",
      "\n",
      "Where do you watch television?\n",
      "在哪儿是你的母親？\n",
      "\n",
      "Where is the Japanese Embassy?\n",
      "哪裡有問題?\n",
      "\n",
      "Where should I put my laundry?\n",
      "你在哪裡看见你的？\n",
      "\n",
      "Where will the bus pick us up?\n",
      "跟我怎麼去那裡？\n",
      "\n",
      "Where's the nearest drugstore?\n",
      "把你的記憶力下來嗎？\n",
      "\n",
      "Who do you suggest we talk to?\n",
      "你跟誰說話呢？\n",
      "\n",
      "Who is going to speak tonight?\n",
      "谁给了我们开始？\n",
      "\n",
      "Who was the letter written to?\n",
      "谁发明信那个消息？\n",
      "\n",
      "Why aren't you coming with us?\n",
      "你為甚麼不鎖門？\n",
      "\n",
      "Why did she go to the station?\n",
      "为什么他不做什么？\n",
      "\n",
      "Why did you come home so late?\n",
      "你為什麼哭了這裡？\n",
      "\n",
      "Why didn't you dance with him?\n",
      "你為甚麼不跟他講？\n",
      "\n",
      "Why don't you have some sushi?\n",
      "你為什麼不舉行派對？\n",
      "\n",
      "Why should I apologize to you?\n",
      "为什么汤姆叫我玛丽？\n",
      "\n",
      "Will you all be here tomorrow?\n",
      "你用的天信被玛丽的回来。\n",
      "\n",
      "Will you go on foot or by bus?\n",
      "你會派人去請醫生來嗎?\n",
      "\n",
      "Will you lend me your bicycle?\n",
      "你來看你的眼睛嗎？\n",
      "\n",
      "Will you stay at home tonight?\n",
      "你要來點不做嗎？\n",
      "\n",
      "Will you switch seats with me?\n",
      "汤姆在出去工作吗？\n",
      "\n",
      "Wine made here is very famous.\n",
      "汤姆是个诚实的男孩。\n",
      "\n",
      "World War I broke out in 1914.\n",
      "他們何時抵達?\n",
      "\n",
      "Would you lend me your pencil?\n",
      "你可以借我你的刀嗎?\n",
      "\n",
      "Would you like me to help you?\n",
      "你用从家下来我来。\n",
      "\n",
      "Would you like some more beef?\n",
      "你要再來點咖啡嗎？\n",
      "\n",
      "Would you like some more beer?\n",
      "你要喝點什麼嗎？\n",
      "\n",
      "Would you like some more cake?\n",
      "你要來點兒沙拉嗎?\n",
      "\n",
      "Would you like to eat with us?\n",
      "你要再來點咖啡嗎？\n",
      "\n",
      "Would you mind coming with me?\n",
      "汤姆，我没找间？\n",
      "\n",
      "Yes, it's such a nice evening.\n",
      "他的衣服總是很臭。\n",
      "\n",
      "You and he are both very kind.\n",
      "你和我是一个高大的男孩。\n",
      "\n",
      "You can borrow my car anytime.\n",
      "你该接受你的我的。\n",
      "\n",
      "You can eat whatever you like.\n",
      "你不能待著。\n",
      "\n",
      "You can stay here if you like.\n",
      "你可以選擇你喜歡的。\n",
      "\n",
      "You can watch TV after supper.\n",
      "你和我是一个高大的。\n",
      "\n",
      "You can't count on their help.\n",
      "你不能待在床上。\n",
      "\n",
      "You could be right, I suppose.\n",
      "你應該得到這個獎金。\n",
      "\n",
      "You don't believe Tom, do you?\n",
      "你不太可以，不是嗎？\n",
      "\n",
      "You don't need to study today.\n",
      "你不能靠湯姆錢嗎？\n",
      "\n",
      "You dropped your handkerchief.\n",
      "你说话，这里工作太人。\n",
      "\n",
      "You have to leave home at six.\n",
      "你必须遵守规则。\n",
      "\n",
      "You look like you're confused.\n",
      "你看起來像湯姆。\n",
      "\n",
      "You may sit wherever you like.\n",
      "你喝得像和快的。\n",
      "\n",
      "You must make up for the loss.\n",
      "你應該和一次睡觉。\n",
      "\n",
      "You must pay attention to him.\n",
      "你不應該出門。\n",
      "\n",
      "You need to go home right now.\n",
      "你和湯姆一起去。\n",
      "\n",
      "You remind me of your brother.\n",
      "你太明天在這裡。\n",
      "\n",
      "You should be more reasonable.\n",
      "你本应该起床早。\n",
      "\n",
      "You should get your car fixed.\n",
      "你该把它的头给汤姆。\n",
      "\n",
      "You should have visited Kyoto.\n",
      "你應該更努力學習。\n",
      "\n",
      "You should have worked harder.\n",
      "你本應該更努力的工作。\n",
      "\n",
      "You should stay at home today.\n",
      "你该去哪里拿游泳。\n",
      "\n",
      "You should stay away from Tom.\n",
      "你應該把我的父親。\n",
      "\n",
      "You should tell him the truth.\n",
      "你该穿一件大衣。\n",
      "\n",
      "You should tell him the truth.\n",
      "你该穿一件大衣。\n",
      "\n",
      "You shouldn't have come alone.\n",
      "我希望你和汤姆结婚。\n",
      "\n",
      "You shouldn't have gone there.\n",
      "你不應該做的。\n",
      "\n",
      "You used to smoke, didn't you?\n",
      "你對我女人沒有他們嗎？\n",
      "\n",
      "You'd better go back home now.\n",
      "你最好尽可能就快就回，我不知道。\n",
      "\n",
      "You'd better not go out today.\n",
      "你最好不要长笑它。\n",
      "\n",
      "You're a better skier than me.\n",
      "你是不老人應該。\n",
      "\n",
      "You're drinking out of my cup.\n",
      "你太多少人去做？\n",
      "\n",
      "You're not satisfied, are you?\n",
      "你不该在这里是吗？\n",
      "\n",
      "You're sick. You have to rest.\n",
      "你在那里。\n",
      "\n",
      "You're very brave, aren't you?\n",
      "你是好女兒。\n",
      "\n",
      "You've got a lot of willpower.\n",
      "你必須派人去請醫生來。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(9900,10000):\n",
    "    test = encoder_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    #print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:14:18.396751Z",
     "start_time": "2020-11-30T03:14:18.391733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 30, 73)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:30:37.564964Z",
     "start_time": "2020-12-04T06:30:37.558980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 163, 73)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_long_sentence_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-04T06:49:36.260192Z",
     "start_time": "2020-12-04T06:48:20.037118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom was admiring my new car at the time the truck crashed into it.\n",
      "你真目標该做什么？\n",
      "\n",
      "You must have been surprised to meet your teacher in such a place.\n",
      "请开傻。\n",
      "\n",
      "You've worked hard for months and have certainly earned a holiday.\n",
      "我们是正朋友。\n",
      "\n",
      "The good die young is an old saying which may or may not be true.\n",
      "，那么。\n",
      "\n",
      "A bookstore in that location wouldn't make enough money to survive.\n",
      "他有！\n",
      "\n",
      "Because of his wealth, he was able to become a member of that club.\n",
      "跑醒！\n",
      "\n",
      "Everyone is anxious to know what has become of the former champion.\n",
      "你可以使用我吗？\n",
      "\n",
      "First off, I'd like you to come with me to a department store sale.\n",
      "请不喜歡它。\n",
      "\n",
      "He always left the problem of his children's education to his wife.\n",
      "你好了嗎？\n",
      "\n",
      "He announced that he would come at once and investigate the matter.\n",
      "过放手。\n",
      "\n",
      "He devoted the last years of his life to writing his autobiography.\n",
      "自然，己是个。\n",
      "\n",
      "He was always annoyed in the city by noises of one sort or another.\n",
      "永远不会下。\n",
      "\n",
      "His wife is in the hospital because she was injured in a car crash.\n",
      "嗨！\n",
      "\n",
      "I'm not a child, but sometimes you talk to me as if I were a child.\n",
      "呢？\n",
      "\n",
      "If you heard her speak English, you would take her for an American.\n",
      "汤姆很高。\n",
      "\n",
      "In this kind of weather, it's best to stay home and not go outside.\n",
      "他有一樣谈。\n",
      "\n",
      "It took me more than two hours to translate a few pages of English.\n",
      "嗨！\n",
      "\n",
      "It was through his influence that she became interested in ecology.\n",
      "气。\n",
      "\n",
      "Please don't forget to put a stamp on the letter before mailing it.\n",
      "么欠这个.\n",
      "\n",
      "The teacher pointed her finger at me and asked me to come with her.\n",
      "你真能跳多吗？\n",
      "\n",
      "The value of the painting was estimated at several million dollars.\n",
      "我试试.\n",
      "\n",
      "There are many more students in the classroom today than yesterday.\n",
      "我有可能！\n",
      "\n",
      "There was a minute of silence and then everybody started screaming.\n",
      "湯姆，快樂。\n",
      "\n",
      "This is a secret just between you and me, so don't let it slip out.\n",
      "我们轉是一个。\n",
      "\n",
      "This problem is too difficult for primary school children to solve.\n",
      "真糕。\n",
      "\n",
      "You should apologize to Dad for not coming home in time for supper.\n",
      "联告诉许了。\n",
      "\n",
      "You're going to wreck your eyesight if you play games all the time.\n",
      "醒醒了！\n",
      "\n",
      "According to the guidebook, this is the best restaurant around here.\n",
      "好嗎？\n",
      "\n",
      "Father makes sure that all the lights are off before he goes to bed.\n",
      "肯定。\n",
      "\n",
      "I can't remember the meaning of the word that I looked up yesterday.\n",
      "真气了吗？\n",
      "\n",
      "I've never lived on a farm, but both of my parents grew up on farms.\n",
      "你真睡着。\n",
      "\n",
      "If two men always have the same opinion, one of them is unnecessary.\n",
      "愛上!\n",
      "\n",
      "In some countries, the punishment for treason can be life in prison.\n",
      "他。\n",
      "\n",
      "In the light of what you told us, I think we should revise our plan.\n",
      "呢。\n",
      "\n",
      "It's difficult for me to understand French when it's spoken quickly.\n",
      "你不快吗？\n",
      "\n",
      "My father is in the habit of reading the newspaper before breakfast.\n",
      "我没见到他。\n",
      "\n",
      "Our task has been easy so far, but it will be difficult from now on.\n",
      "全问輕人。\n",
      "\n",
      "The death penalty had been done away with in many states in the USA.\n",
      "告，我的吗？\n",
      "\n",
      "The flash wasn't working, so he couldn't take a picture in the dark.\n",
      "请！\n",
      "\n",
      "The only difference between a bad cook and a poisoner is the intent.\n",
      "我們坐哪裡？\n",
      "\n",
      "Tom asked me to tell you he didn't plan on going to Boston with you.\n",
      "嗨！\n",
      "\n",
      "Do you know when they will arrive? \"At eleven-thirty this evening.\"\n",
      "這把手錶在哪裡？\n",
      "\n",
      "Always do right. This will gratify some people and astonish the rest.\n",
      "你可以慢慢来。\n",
      "\n",
      "Everybody talks about the weather, but nobody does anything about it.\n",
      "我真相嗎？\n",
      "\n",
      "He and I were inseparable friends during our time together in school.\n",
      "你們一起迷！\n",
      "\n",
      "His intelligence and experience enabled him to deal with the trouble.\n",
      "为他。\n",
      "\n",
      "I think it's dangerous to climb a mountain on a day when it's stormy.\n",
      "你真的吗？\n",
      "\n",
      "If it had not been for your help, I couldn't have completed the work.\n",
      "你真忙。\n",
      "\n",
      "In a few minutes we'll be landing at New Tokyo International Airport.\n",
      "我可以现在这儿吗？\n",
      "\n",
      "It's clear that there's a rather strong disagreement between the two.\n",
      "你真奇怪。\n",
      "\n",
      "Most Americans do not object to my calling them by their first names.\n",
      "快点很大。\n",
      "\n",
      "Nobody's going to shed any tears if that old building gets torn down.\n",
      "把你！\n",
      "\n",
      "She has a good command of English though she was brought up in Japan.\n",
      "服平我。\n",
      "\n",
      "She took full advantage of her stay in London to improve her English.\n",
      "他有点活面吗？\n",
      "\n",
      "The taller the tree, the more likely it is to be struck by lightning.\n",
      "妈迎我来。\n",
      "\n",
      "There is nothing worse than doing something in a half-hearted manner.\n",
      "他有一个头吧。\n",
      "\n",
      "We've received a lot of applications in answer to our advertisements.\n",
      "我们可能！\n",
      "\n",
      "Because of heavy snow, the plane from Beijing arrived 20 minutes late.\n",
      "出去，你的。\n",
      "\n",
      "Can you describe to me the difference between black tea and green tea?\n",
      "真是嗎？\n",
      "\n",
      "Don't worry! Even if I drink, it doesn't have an effect on my driving.\n",
      "真是了嗎？\n",
      "\n",
      "Had he known what was about to happen, he would have changed his plan.\n",
      "我是个接的。\n",
      "\n",
      "I think you will find it convenient to put a short-cut on the desktop.\n",
      "你会唱歌嗎？\n",
      "\n",
      "I want a cellular phone, but I don't have enough money to pay for one.\n",
      "服我喜欢你。\n",
      "\n",
      "I will have finished reading this novel by the time you come tomorrow.\n",
      "今天氣。\n",
      "\n",
      "I've something interesting to tell you that you might find surprising.\n",
      "我會帶你。\n",
      "\n",
      "It was raining when we left, but by the time we arrived, it was sunny.\n",
      "我們的工作。\n",
      "\n",
      "Rather than live a hundred years as a rabbit, live one day as a tiger.\n",
      "告诉你。\n",
      "\n",
      "Tom wanted to stay home and relax instead of hiking with his children.\n",
      "我们试试。\n",
      "\n",
      "What's this song? I've heard it before, but I can't remember the name.\n",
      "平平的？\n",
      "\n",
      "As is evident from the data, smoking is not decreasing among the young.\n",
      "叫我们爱汤姆。\n",
      "\n",
      "Because it is written in simple English even a child can understand it.\n",
      "湯姆像等一會兒。\n",
      "\n",
      "Does any other country fan the flames of patriotism as much as America?\n",
      "請你在这些。\n",
      "\n",
      "I was nine years old when I asked my mom if Santa Claus really existed.\n",
      "把手举起来！\n",
      "\n",
      "I'm a foreigner and I don't know Czech very well. Please, speak slowly.\n",
      "当手举！\n",
      "\n",
      "If it's at all possible, I'd like you to take part in the next meeting.\n",
      "我们在拥房裡。\n",
      "\n",
      "If you enjoy the work you do, you have something worth more than money.\n",
      "噢，真是真乐。\n",
      "\n",
      "It was not until I had a baby myself that I knew what mother's love is.\n",
      "一点好吧。\n",
      "\n",
      "Kindness is the language which the deaf can hear and the blind can see.\n",
      "美死了吗？\n",
      "\n",
      "Mary came home from school in tears because her friends had teased her.\n",
      "你嗎？\n",
      "\n",
      "My father was no less affectionate and tender to me than my mother was.\n",
      "你必須嗎？\n",
      "\n",
      "Now's the time to decide whether you really want to get married or not.\n",
      "麻煩！\n",
      "\n",
      "People show up bright on an infrared camera because of their body heat.\n",
      "建我。\n",
      "\n",
      "The police have been searching for the stolen goods for almost a month.\n",
      "我们试将吗？\n",
      "\n",
      "They told me that I would feel a little better if I took this medicine.\n",
      "来一点儿子吗？\n",
      "\n",
      "Tom couldn't go to college because his family didn't have enough money.\n",
      "他！\n",
      "\n",
      "When his food supply ran short, he had to look for a new place to live.\n",
      "害你。\n",
      "\n",
      "While I was reading in bed last night, I fell asleep with the light on.\n",
      "如果它是明的地方。\n",
      "\n",
      "Where have you been? \"I have been to the station to see a friend off.\"\n",
      "跑了。\n",
      "\n",
      "Her eyes shone with joy when she saw that her mother was not mad at her.\n",
      "我很久嗎？\n",
      "\n",
      "I can place the palms of my hands on the floor without bending my knees.\n",
      "你不轉動嗎？\n",
      "\n",
      "I was planning on going to the beach today, but then it started to rain.\n",
      "你忙嗎？\n",
      "\n",
      "If we knew what we were doing, it wouldn't be called research, would it?\n",
      "我们在听泳。\n",
      "\n",
      "If you want to go, then go. If you don't want to, then it's no big deal.\n",
      "我可以幫忙。\n",
      "\n",
      "In the U.S., most people can vote when they reach eighteen years of age.\n",
      "他在麻烦了。\n",
      "\n",
      "It is the things that we do not possess which seem to us most desirable.\n",
      "汤姆是大的话。\n",
      "\n",
      "Rather than cutting down on cigarettes, why don't you just give them up?\n",
      "把你已电话回来。\n",
      "\n",
      "Sociopaths rarely display remorse or feelings of guilt for their crimes.\n",
      "美被了张回家。\n",
      "\n",
      "Tom can't account for his whereabouts on the day that Mary was murdered.\n",
      "游泳。\n",
      "\n",
      "Tom never forgets to give his wife flowers on their wedding anniversary.\n",
      "他一樣。\n",
      "\n",
      "Tom was able to make himself understood in French when he visited Paris.\n",
      "我们準行了。\n",
      "\n",
      "We were talking about something at that time, but I don't remember what.\n",
      "你感兴吗？\n",
      "\n",
      "You shouldn't share too much private information on the social networks.\n",
      "步吧？\n",
      "\n",
      "After school, I go to an English school to practice English conversation.\n",
      "恐合。\n",
      "\n",
      "I think you'll have very little difficulty in getting a driver's license.\n",
      "你可以做了吗？\n",
      "\n",
      "I thought we had found the perfect hiding place, but the police found us.\n",
      "你真的吗？\n",
      "\n",
      "I'd like to know the phone number of the nearest American Express office.\n",
      "把它！你\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She visits the dentist on a regular basis, so she seldom gets toothaches.\n",
      "不好。\n",
      "\n",
      "To make matters worse, he isn't even conscious of annoying his neighbors.\n",
      "他是我的菜。\n",
      "\n",
      "You seem to be prejudiced against ideas that come from foreign countries.\n",
      "很棒！\n",
      "\n",
      "If a sick person folds one thousand paper cranes, her wish will come true.\n",
      "往帶汽車。\n",
      "\n",
      "It's hard to believe that Tom wasn't aware that Mary was in love with him.\n",
      "为他们。\n",
      "\n",
      "Tom returned to his hometown to visit his parents during the summer break.\n",
      "他有一定很激。\n",
      "\n",
      "You're much less likely to get a good position if you don't speak English.\n",
      "你可以做嗎？\n",
      "\n",
      "After asking for my key at the front desk, I took the elevator to my floor.\n",
      "蠢了一雪！\n",
      "\n",
      "English has now become the common language of several nations in the world.\n",
      "！有你吗？\n",
      "\n",
      "Outside the school, she saw people with no homes living in cardboard boxes.\n",
      "试试！\n",
      "\n",
      "The Prime Minister's speech was calculated to anger the opposition parties.\n",
      "这个，好是我的工作乡。\n",
      "\n",
      "The good thing about this electronic dictionary is that it's easy to carry.\n",
      "醒醒！\n",
      "\n",
      "The lady really flipped out when she learned she had won a million dollars.\n",
      "我们吧。\n",
      "\n",
      "We apologize for the delay and regret any inconvenience it may have caused.\n",
      "？\n",
      "\n",
      "According to newspaper reports, there was an airplane accident last evening.\n",
      "请不用你真说话。\n",
      "\n",
      "After he had graduated from the university, he taught English for two years.\n",
      "过得恐！\n",
      "\n",
      "If a man had 11 sheep and all but 9 died, how many sheep would he have left?\n",
      "不能吧。\n",
      "\n",
      "It would take me too much time to explain to you why it's not going to work.\n",
      "醒你的一個忙子做了。\n",
      "\n",
      "The statue of Hachiko, the faithful dog, stands in front of Shibuya Station.\n",
      "到烦儿。\n",
      "\n",
      "A person views things differently according to whether they are rich or poor.\n",
      "你！\n",
      "\n",
      "Although the government refuses to admit it, its economic policy is in ruins.\n",
      "醒你的名字？\n",
      "\n",
      "Mary tied an apron around her waist and then took the turkey out of the oven.\n",
      "你以以果汁吗？\n",
      "\n",
      "People look at things differently depending on whether they are rich or poor.\n",
      "賣你。\n",
      "\n",
      "The population of London is much greater than that of any other British city.\n",
      "手持安靜。\n",
      "\n",
      "They consider it impolite to disagree with someone they don't know very well.\n",
      "我樂意。\n",
      "\n",
      "Three out of four Americans believe in the existence of paranormal phenomena.\n",
      "我很明疼。\n",
      "\n",
      "Tom came to the conclusion that no matter what he did, Mary wouldn't like it.\n",
      "跳！\n",
      "\n",
      "All students of English should have a good English-English dictionary at hand.\n",
      "真试了。\n",
      "\n",
      "Eighty percent of all information on computers around the world is in English.\n",
      "做个！\n",
      "\n",
      "I've had a scratchy throat since this morning. I wonder if I've caught a cold.\n",
      "我們在吃午餐。\n",
      "\n",
      "If it looks like an apple and it tastes like an apple, it's probably an apple.\n",
      "你就喜歡你真的。\n",
      "\n",
      "The world is just like a book, and every step you take is like turning a page.\n",
      "你有好嗎？\n",
      "\n",
      "Today, I was supposed to study at the library but I woke up around 12 o'clock.\n",
      "好很好!\n",
      "\n",
      "Tom can write almost like a native speaker, but his pronunciation is terrible.\n",
      "好出席吗？\n",
      "\n",
      "Tom did the best he could, but he wasn't able to get a higher grade than Mary.\n",
      "他有麻烦。\n",
      "\n",
      "As the train came to a halt, all of the passengers wondered what was happening.\n",
      "我们来试试。\n",
      "\n",
      "Charles Lindbergh made the first solo flight across the Atlantic Ocean in 1927.\n",
      "把那裡很好。\n",
      "\n",
      "His scores are always better than mine, even though he doesn't study very much.\n",
      "请相信那太好？\n",
      "\n",
      "I don't have a lot of work, but it's enough to keep me in the office this week.\n",
      "變美味。\n",
      "\n",
      "I returned the books I borrowed from the library, and I borrowed some new ones.\n",
      "真好嗎？\n",
      "\n",
      "Publication of the article was timed to coincide with the professor's birthday.\n",
      "他在那裡我。\n",
      "\n",
      "She's popular, not because she's beautiful, but because she's kind to everyone.\n",
      "停好。\n",
      "\n",
      "When I was in London last year, someone broke into my room and stole my wallet.\n",
      "保持喜漂亮的。\n",
      "\n",
      "At the time there were no native English speakers teaching in any public school.\n",
      "好！\n",
      "\n",
      "Rio de Janeiro is perfectly safe as long as you stay out of the dangerous areas.\n",
      "停手！\n",
      "\n",
      "She was asked to convince him to get his son or someone else to paint the house.\n",
      "把手錶在哪裡？\n",
      "\n",
      "Even though I studied English for 6 years in school, I'm not good at speaking it.\n",
      "你出去嗎？\n",
      "\n",
      "The ages of the two children put together was equivalent to that of their father.\n",
      "他们来试试。\n",
      "\n",
      "To the man who only has a hammer in the toolkit, every problem looks like a nail.\n",
      "试试试。\n",
      "\n",
      "Being a good conversationalist does not just mean being a good speaker of English.\n",
      "我們能很多。\n",
      "\n",
      "Manholes are round because that way they won't accidentally fall through the hole.\n",
      "小心狗。\n",
      "\n",
      "You should have known better than to take an examination without preparing for it.\n",
      "我们一会把你的帽子。\n",
      "\n",
      "I've just spoken to your French teacher and he says you're doing well in his class.\n",
      "我们已经过去了。\n",
      "\n",
      "We'll need a head hunting agency to find the right man for this executive position.\n",
      "再见！\n",
      "\n",
      "He came back not because he was homesick, but because he was running short of money.\n",
      "请抓到你一去。\n",
      "\n",
      "If you want something to be done right, sometimes you've just got to do it yourself.\n",
      "你們很高放棄。\n",
      "\n",
      "Why don't we stop arguing over these piddling matters and get to the issues at hand?\n",
      "很棒！\n",
      "\n",
      "A growing child who doesn't seem to have much energy perhaps needs medical attention.\n",
      "告告訴你。\n",
      "\n",
      "All things considered, I think you should go back home and take care of your parents.\n",
      "当！\n",
      "\n",
      "In London, the police are always worried about finding a bomb on the train or subway.\n",
      "试试试试。\n",
      "\n",
      "Ladies and gentlemen, due to an accident at the airport, our arrival will be delayed.\n",
      "叫警察！\n",
      "\n",
      "The number of people on Facebook is greater than the population of the United States.\n",
      "我可以轉小一些咖啡。\n",
      "\n",
      "Democracy is the worst form of government, except all the others that have been tried.\n",
      "。\n",
      "\n",
      "At lunchtime today, our usual restaurant was closed because of a funeral in the family.\n",
      "汤不可能！\n",
      "\n",
      "Tom's mother is a nurse at the hospital that's across the street from where Mary lives.\n",
      "他！你了！\n",
      "\n",
      "Eat a live frog every morning, and nothing worse will happen to you the rest of the day.\n",
      "我相信嗎？\n",
      "\n",
      "I had to change clothes because what I was wearing wasn't appropriate for the situation.\n",
      "我的房间。\n",
      "\n",
      "Computers are certainly playing an important role in our life, whether we like it or not.\n",
      "嗨！你不闭!\n",
      "\n",
      "One out of 455 women doesn't realize she's pregnant until the twentieth week of pregnancy.\n",
      "真是。\n",
      "\n",
      "Because of its origins, Canadian English has features of both American and British English.\n",
      "不会。\n",
      "\n",
      "I like this picture, not just because it is famous, but because it really is a masterpiece.\n",
      "真好嗎？\n",
      "\n",
      "For the other 600 million people, English is either a second language or a foreign language.\n",
      "轻试这个好吧。\n",
      "\n",
      "Lonely people tend to be afraid of meeting others, which ensures they will always be lonely.\n",
      "爱是谁的，?\n",
      "\n",
      "When people meet, first impressions determine more than 50 percent of whatever happens next.\n",
      "告訴你真的嗎？\n",
      "\n",
      "Right now, we have blueberries, blackberries, cherries, strawberries, peaches and nectarines.\n",
      "叫什么名字吧。\n",
      "\n",
      "Throughout the five years of painful cancer treatments, he managed to keep a stiff upper lip.\n",
      "我喜歡试。\n",
      "\n",
      "When we started out, our band could only find small clubs in small cities that would hire us.\n",
      "醒醒！\n",
      "\n",
      "Abraham Lincoln, the 16th president of the United States, was born in a log cabin in Kentucky.\n",
      "过你。\n",
      "\n",
      "For quantities of 20 or more, we can allow you a special discount of 10% on the prices quoted.\n",
      "快你。\n",
      "\n",
      "I can't believe you are eating something the doctor has told you repeatedly you shouldn't eat.\n",
      "汤姆。\n",
      "\n",
      "If we were supposed to talk more than listen, we would have been given two mouths and one ear.\n",
      "你真丢嗎？\n",
      "\n",
      "Optimists see opportunities in disasters while pessimists find disasters in every opportunity.\n",
      "的。\n",
      "\n",
      "Tom tried to return the swimsuit for a larger size, but the clerk told him that wasn't allowed.\n",
      "很棒！\n",
      "\n",
      "Some people clung to tree branches for several hours to avoid being washed away by the floodwaters.\n",
      "動太害了。\n",
      "\n",
      "The handyman was supposed to arrive at twelve noon, but got stuck in a traffic jam for a few hours.\n",
      "我会留给你。\n",
      "\n",
      "My parents usually speak to each other in French, even though my mother is a native English speaker.\n",
      "你好嗎？\n",
      "\n",
      "The large crowd roared in approval as Mark Knopfler played the first few bars of \"Money for Nothing\".\n",
      "等他很喜欢。\n",
      "\n",
      "Tom's daughter pretended not to know him when he came to pick her up from school in his battered old car.\n",
      "他不成功。\n",
      "\n",
      "The Japanese Parliament today officially elected Ryoutarou Hashimoto as the country's 52nd prime minister.\n",
      "你真能跑嗎？\n",
      "\n",
      "Last year in the Philippines, earthquakes and tidal waves resulted in the deaths of more than 6,000 people.\n",
      "六點開始嗎?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My mother speaks French better than my father speaks English, so they usually speak to each other in French.\n",
      "她好吗？\n",
      "\n",
      "Even now, I occasionally think I'd like to see you. Not the you that you are today, but the you I remember from the past.\n",
      "你爱上出身。\n",
      "\n",
      "If a person has not had a chance to acquire his target language by the time he's an adult, he's unlikely to be able to reach native speaker level in that language.\n",
      "叫ar拿好嗎?\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-df8ef29a9306>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_chinese\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_infer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_infer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOUTPUT_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOUTPUT_FEATURE_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_texts_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0,200):\n",
    "    test = test_long_sentence_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    #print(input_texts[i],'\\n---\\n',target_texts[i],'\\n---\\n',out)\n",
    "    print(input_texts_test[i])\n",
    "    print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
